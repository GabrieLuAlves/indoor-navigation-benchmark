{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1962daf",
   "metadata": {
    "_cell_guid": "46070462-b7f4-4b15-a4d9-44c137eef69f",
    "_uuid": "52bd373b-06fb-440c-9483-deea28193b49",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:09.094325Z",
     "iopub.status.busy": "2025-06-28T23:55:09.093936Z",
     "iopub.status.idle": "2025-06-28T23:55:28.101549Z",
     "shell.execute_reply": "2025-06-28T23:55:28.100565Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 19.017758,
     "end_time": "2025-06-28T23:55:28.103317",
     "exception": false,
     "start_time": "2025-06-28T23:55:09.085559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 23:55:14.293921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751154914.542341      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751154914.609549      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9d02e",
   "metadata": {
    "_cell_guid": "3338e322-2959-4ad2-b3be-c17a32a1e169",
    "_uuid": "21023635-b155-46ea-b788-4bb5c3d6265f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004984,
     "end_time": "2025-06-28T23:55:28.114176",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.109192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224b8c50",
   "metadata": {
    "_cell_guid": "2bbe6b55-0ab9-4f99-94f8-02edd972a906",
    "_uuid": "5452c999-be68-4f18-9c63-5a0578c1f722",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.126633Z",
     "iopub.status.busy": "2025-06-28T23:55:28.125991Z",
     "iopub.status.idle": "2025-06-28T23:55:28.136755Z",
     "shell.execute_reply": "2025-06-28T23:55:28.135621Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018687,
     "end_time": "2025-06-28T23:55:28.138274",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.119587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "    \n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "@tf.function\n",
    "def eva(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "\n",
    "    numerator = tf.math.reduce_variance(y_true - y_pred)\n",
    "    denominator = tf.math.reduce_variance(y_true) + tf.keras.backend.epsilon()\n",
    "    \n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "@tf.function\n",
    "def r2_score(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "    \n",
    "    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    \n",
    "    return 1 - (ss_res / (ss_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b85a1",
   "metadata": {
    "_cell_guid": "a033fd0a-11ba-49cf-b8dc-d690bee50ca1",
    "_uuid": "6d9bdfc4-6c43-448a-a91b-471ca4a22332",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004933,
     "end_time": "2025-06-28T23:55:28.148782",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.143849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. ResNet 8/18/34 construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b4907b",
   "metadata": {
    "_cell_guid": "b7e2c34b-3e37-480b-abdf-5b6d88e97f2a",
    "_uuid": "b18400fe-6f61-41f3-80bb-b0536922193c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.160924Z",
     "iopub.status.busy": "2025-06-28T23:55:28.160591Z",
     "iopub.status.idle": "2025-06-28T23:55:28.167201Z",
     "shell.execute_reply": "2025-06-28T23:55:28.166316Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014721,
     "end_time": "2025-06-28T23:55:28.168684",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.153963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resnet_block(x, filters, stride=1, use_projection=False):\n",
    "    shortcut = x\n",
    "\n",
    "    x = keras.layers.Conv2D(filters, 3, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters, 3, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if use_projection:\n",
    "        shortcut = keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n",
    "        shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Add()([x, shortcut])\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f7a652",
   "metadata": {
    "_cell_guid": "f10ef329-9949-4fb1-9851-4e0cd42eacb1",
    "_uuid": "793f7961-14b7-4716-afb9-d89646cdecf0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.180633Z",
     "iopub.status.busy": "2025-06-28T23:55:28.180277Z",
     "iopub.status.idle": "2025-06-28T23:55:28.186315Z",
     "shell.execute_reply": "2025-06-28T23:55:28.185574Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013625,
     "end_time": "2025-06-28T23:55:28.187694",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.174069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet8_DroNet(input_shape=(200, 200, 1), dropout_rate=0.3):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = keras.layers.Conv2D(32, 5, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    x = resnet_block(x, 32)\n",
    "    x = resnet_block(x, 32)\n",
    "\n",
    "    x = resnet_block(x, 64, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 128)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet8_DroNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47b7ed6",
   "metadata": {
    "_cell_guid": "1ab4574a-0008-4f55-8522-d41c19d1c757",
    "_uuid": "d08c3a95-1e8d-43a2-b476-edeba21417bf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.199480Z",
     "iopub.status.busy": "2025-06-28T23:55:28.199155Z",
     "iopub.status.idle": "2025-06-28T23:55:28.205663Z",
     "shell.execute_reply": "2025-06-28T23:55:28.204950Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014085,
     "end_time": "2025-06-28T23:55:28.207047",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.192962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet18(input_shape=(224, 224, 3)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Conv2_x\n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "    # Conv3_x\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 128)\n",
    "\n",
    "    # Conv4_x\n",
    "    x = resnet_block(x, 256, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 256)\n",
    "\n",
    "    # Conv5_x\n",
    "    x = resnet_block(x, 512, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 512)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet18_backbone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd22809",
   "metadata": {
    "_cell_guid": "4e15582f-a90d-4bbf-9063-5c25ae37fbf1",
    "_uuid": "4506a044-df15-4966-8b32-2e0e5a6b2811",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.218690Z",
     "iopub.status.busy": "2025-06-28T23:55:28.218336Z",
     "iopub.status.idle": "2025-06-28T23:55:28.225609Z",
     "shell.execute_reply": "2025-06-28T23:55:28.224588Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014738,
     "end_time": "2025-06-28T23:55:28.227079",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.212341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet34(input_shape=(224, 224, 3)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Conv2_x (3 blocks)\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 64)\n",
    "\n",
    "    # Conv3_x (4 blocks)\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 128)\n",
    "\n",
    "    # Conv4_x (6 blocks)\n",
    "    x = resnet_block(x, 256, stride=2, use_projection=True)\n",
    "    for _ in range(5):\n",
    "        x = resnet_block(x, 256)\n",
    "\n",
    "    # Conv5_x (3 blocks)\n",
    "    x = resnet_block(x, 512, stride=2, use_projection=True)\n",
    "    for _ in range(2):\n",
    "        x = resnet_block(x, 512)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet34_backbone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54673673",
   "metadata": {
    "_cell_guid": "5541b060-36b4-42fe-b425-7bfd72e7b45e",
    "_uuid": "510600d1-1d77-454a-8011-5371ea499712",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004968,
     "end_time": "2025-06-28T23:55:28.237317",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.232349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Grid search configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1446b28",
   "metadata": {
    "_cell_guid": "6f66a903-0170-417a-8288-2314e82512ad",
    "_uuid": "5ab4cb0d-2d3b-4203-86b9-c9ed8717eaf7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.248939Z",
     "iopub.status.busy": "2025-06-28T23:55:28.248576Z",
     "iopub.status.idle": "2025-06-28T23:55:28.253182Z",
     "shell.execute_reply": "2025-06-28T23:55:28.252450Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012159,
     "end_time": "2025-06-28T23:55:28.254528",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.242369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "configurations = list(product([1e-2, 1e-3, 1e-4], [32, 64, 128]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb06b1b",
   "metadata": {
    "_cell_guid": "befc604b-fe79-4f99-8cb6-9eb35c1e2b67",
    "_uuid": "976bf65c-b852-4ea8-8d65-525c9b981ced",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.005324,
     "end_time": "2025-06-28T23:55:28.265073",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.259749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf608a4",
   "metadata": {
    "_cell_guid": "f7eddf37-fbff-433b-8efb-20507f4d2b8f",
    "_uuid": "cfd37596-4204-41a7-9539-264d09469b70",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.276325Z",
     "iopub.status.busy": "2025-06-28T23:55:28.276010Z",
     "iopub.status.idle": "2025-06-28T23:55:28.284230Z",
     "shell.execute_reply": "2025-06-28T23:55:28.283359Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015723,
     "end_time": "2025-06-28T23:55:28.285726",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.270003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_descriptions = [\n",
    "    {\n",
    "        \"name\": \"DroNet-500\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-8\",\n",
    "            \"weights\": \"dronet\"\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": (200, 200, 1),\n",
    "            \"grayscale\": True\n",
    "        },\n",
    "        \"head_description\": [\n",
    "            (32, True, False),\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DroNet-600\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-8\",\n",
    "            \"weights\": \"dronet\"\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": (200, 200, 1),\n",
    "            \"grayscale\": True\n",
    "        },\n",
    "        \"head_description\": [\n",
    "            (64, True, False),\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Format verification\n",
    "for model_description in models_descriptions:\n",
    "    if \"backbone\" not in model_description:\n",
    "        raise KeyError(\"backbone not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"name\" not in model_description[\"backbone\"]:\n",
    "        raise KeyError(\"backbone.name not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"weights\" not in model_description[\"backbone\"]:\n",
    "        model_description[\"backbone\"][\"weights\"] = None\n",
    "    \n",
    "    if \"name\" not in model_description:\n",
    "        model_description[\"name\"] = model_description[\"backbone\"]\n",
    "\n",
    "    if \"head_description\" not in model_description:\n",
    "        model_description[\"head_description\"] = []\n",
    "\n",
    "    if \"weights\" not in model_description:\n",
    "        model_description[\"weights\"] = None\n",
    "\n",
    "    if \"input\" not in model_description:\n",
    "        raise KeyError(\"input not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"shape\" not in model_description[\"input\"]:\n",
    "        raise KeyError(\"input.shape not specified at:\\n\" + str(model_description))\n",
    "    \n",
    "    if \"grayscale\" not in model_description[\"input\"]:\n",
    "        model_description[\"input\"][\"grayscale\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f41a74",
   "metadata": {
    "_cell_guid": "8053b71d-50ff-4861-af2f-039eb0efc7c0",
    "_uuid": "9751bcfc-b5b2-4bd1-87e6-92285fb23b7d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004945,
     "end_time": "2025-06-28T23:55:28.295990",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.291045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load dataset and build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae42ad8a",
   "metadata": {
    "_cell_guid": "5555623d-1250-4072-af6e-4ca6b6a5d197",
    "_uuid": "cc680d39-133c-4d96-934e-1fb8ca9009d8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.307670Z",
     "iopub.status.busy": "2025-06-28T23:55:28.307213Z",
     "iopub.status.idle": "2025-06-28T23:55:28.312834Z",
     "shell.execute_reply": "2025-06-28T23:55:28.311960Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013237,
     "end_time": "2025-06-28T23:55:28.314348",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.301111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_samples_dataframe(path: str):\n",
    "    images_folder = os.path.join(path, \"images\")\n",
    "\n",
    "    samples_df = pd.read_csv(\n",
    "        os.path.join(path, \"market_dataset_xy.txt\"),\n",
    "        sep=\" \",\n",
    "        header=None,\n",
    "        names=[\"file path\", \"_\", \"datetime\", \"vel_y\", \"vel_x\"]\n",
    "    )\n",
    "\n",
    "    samples_df[\"file path\"] = (\n",
    "        samples_df[\"file path\"]\n",
    "        .apply(lambda image_name: os.path.join(path, \"images\", image_name))\n",
    "    )\n",
    "    \n",
    "    return samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0aa444d",
   "metadata": {
    "_cell_guid": "adf866ea-2822-48b8-a954-b4be212d53af",
    "_uuid": "513d809a-65b0-423f-87e3-679285f73bf0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.326699Z",
     "iopub.status.busy": "2025-06-28T23:55:28.325873Z",
     "iopub.status.idle": "2025-06-28T23:55:28.333200Z",
     "shell.execute_reply": "2025-06-28T23:55:28.332337Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015006,
     "end_time": "2025-06-28T23:55:28.334663",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.319657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def augment(image, label):\n",
    "    # Brightness and contrast\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    \n",
    "    # Flip horizontally\n",
    "    do_flip = tf.random.uniform([]) > 0.5\n",
    "    image = tf.cond(do_flip, lambda: tf.image.flip_left_right(image), lambda: image)\n",
    "    \n",
    "    vel_x = tf.cond(do_flip, lambda: -label[\"vel_x\"], lambda: label[\"vel_x\"])\n",
    "    vel_y = label[\"vel_y\"]\n",
    "    \n",
    "    # Optionally add noise\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.025)\n",
    "    image = image + noise\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    return image, {\"vel_x\": vel_x, \"vel_y\": vel_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6abe850",
   "metadata": {
    "_cell_guid": "ad4a4a1f-930e-4277-80b1-5b6baac7f826",
    "_uuid": "c96bf886-1c0d-4aa4-b406-b6f1ae910f6d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.346356Z",
     "iopub.status.busy": "2025-06-28T23:55:28.346070Z",
     "iopub.status.idle": "2025-06-28T23:55:28.351868Z",
     "shell.execute_reply": "2025-06-28T23:55:28.350976Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013449,
     "end_time": "2025-06-28T23:55:28.353373",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.339924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(path, mode=\"color\"):\n",
    "    image = tf.io.read_file(path)\n",
    "\n",
    "    if mode == \"color\":\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    elif mode == \"grayscale1\":\n",
    "        image = tf.image.decode_jpeg(image, channels=1)\n",
    "\n",
    "    elif mode == \"grayscale3\":\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a95a26d",
   "metadata": {
    "_cell_guid": "45c54901-4826-4fcf-9ce8-aa64653e769e",
    "_uuid": "ef17faa6-b5d9-4603-818e-12790606b097",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.365331Z",
     "iopub.status.busy": "2025-06-28T23:55:28.365042Z",
     "iopub.status.idle": "2025-06-28T23:55:28.374665Z",
     "shell.execute_reply": "2025-06-28T23:55:28.373664Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017598,
     "end_time": "2025-06-28T23:55:28.376316",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.358718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_train_val_test_datasets(samples_dataframe, input_description: dict, seed=42):\n",
    "    # Split\n",
    "    df_train, df_temp = train_test_split(samples_dataframe, test_size=0.4, random_state=seed)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=seed)\n",
    "\n",
    "    resolution = input_description[\"shape\"][:2]\n",
    "    channels = input_description[\"shape\"][2]\n",
    "\n",
    "    if not input_description[\"grayscale\"]:\n",
    "        mode = \"color\"\n",
    "    elif channels == 1:\n",
    "        mode = \"grayscale1\"\n",
    "    elif channels == 3:\n",
    "        mode = \"grayscale3\"\n",
    "\n",
    "    def process_sample(path, label):\n",
    "        image = load_image(path, mode=mode)\n",
    "        image = tf.image.resize(image, resolution)\n",
    "        image.set_shape(input_description[\"shape\"])\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def df_to_tf_dataset(df, training=False):\n",
    "        paths = tf.constant(df[\"file path\"].tolist())\n",
    "        vel_x = tf.constant(df[\"vel_x\"].astype(\"float32\").tolist())\n",
    "        vel_y = tf.constant(df[\"vel_y\"].astype(\"float32\").tolist())\n",
    "    \n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, {\"vel_x\": vel_x, \"vel_y\": vel_y}))\n",
    "    \n",
    "        ds = ds.map(process_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.cache()\n",
    "    \n",
    "        if training:\n",
    "            ds = ds.shuffle(len(df), reshuffle_each_iteration=True)\n",
    "            ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            \n",
    "        return ds\n",
    "\n",
    "    return {\n",
    "        \"train\": df_to_tf_dataset(df_train, training=True),\n",
    "        \"val\":   df_to_tf_dataset(df_val, training=False),\n",
    "        \"test\":  df_to_tf_dataset(df_test, training=False),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c64d4b20",
   "metadata": {
    "_cell_guid": "b2e5a695-5c16-4993-92eb-68c327fbc94a",
    "_uuid": "37c07429-c36f-4739-80ac-cc544f823bcc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.388894Z",
     "iopub.status.busy": "2025-06-28T23:55:28.388497Z",
     "iopub.status.idle": "2025-06-28T23:55:28.397279Z",
     "shell.execute_reply": "2025-06-28T23:55:28.396453Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017431,
     "end_time": "2025-06-28T23:55:28.399018",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.381587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def instantiate_backbone(backbone_name, weights=None):\n",
    "    if backbone_name == \"ResNet-8\":\n",
    "        if weights:\n",
    "            if weights == \"dronet\":\n",
    "                return keras.models.load_model(\"/kaggle/input/marketplace-navigation-dataset/model.keras\")\n",
    "            else:\n",
    "                print(\"[INFO] could not find weights for ResNet-8\")\n",
    "        return ResNet8_DroNet(input_shape=(200, 200, 1))\n",
    "    \n",
    "    if backbone_name == \"ResNet-18\":\n",
    "        if weights is not None:\n",
    "            print(\"[INFO] No pre-trained weights for ResNet-18\")\n",
    "        return ResNet18(input_shape=(224, 224, 3))\n",
    "        \n",
    "    if backbone_name == \"ResNet-34\":\n",
    "        if weights is not None:\n",
    "            print(\"[INFO] No pre-trained weights for ResNet-34\")\n",
    "        return ResNet34(input_shape=(224, 224, 3))\n",
    "\n",
    "    if backbone_name == \"ResNet-50\":\n",
    "        return keras.applications.ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\",\n",
    "            pooling=None,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"ResNet-50V2\":\n",
    "        return keras.applications.ResNet50V2(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\",\n",
    "            pooling=None,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"MobileNet\":\n",
    "        return keras.applications.MobileNet(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\",\n",
    "            pooling=None,\n",
    "            alpha=1.0,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"MobileNetV2\":\n",
    "        return keras.applications.MobileNetV2(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\",\n",
    "            pooling=None,\n",
    "            alpha=1.0,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"EfficientNetB0\":\n",
    "        return keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\",\n",
    "            pooling=None,\n",
    "        )\n",
    "    \n",
    "    raise ValueError(f\"Backbone {backbone_name} not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c05cce",
   "metadata": {
    "_cell_guid": "3a8055dd-c1af-4d03-82b5-d851bdbb6b59",
    "_uuid": "f0ed5477-06af-4532-8db7-a6b1d08aabcb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.410974Z",
     "iopub.status.busy": "2025-06-28T23:55:28.410609Z",
     "iopub.status.idle": "2025-06-28T23:55:28.419979Z",
     "shell.execute_reply": "2025-06-28T23:55:28.419019Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017229,
     "end_time": "2025-06-28T23:55:28.421613",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.404384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(model_description: dict):\n",
    "    input_shape = model_description[\"input\"][\"shape\"]\n",
    "    input_shape = tuple(input_shape)\n",
    "\n",
    "    backbone_name = model_description[\"backbone\"][\"name\"]\n",
    "    backbone_weights = model_description[\"backbone\"][\"weights\"]\n",
    "\n",
    "    PREPROCESS = {\n",
    "        \"MobileNet\":       keras.applications.mobilenet.preprocess_input,\n",
    "        \"MobileNetV2\":     keras.applications.mobilenet_v2.preprocess_input,\n",
    "        \"ResNet-50\":       lambda x: keras.applications.resnet.preprocess_input(x, mode=\"caffe\"),\n",
    "        \"ResNet-50V2\":     keras.applications.resnet_v2.preprocess_input,\n",
    "        \"EfficientNetB0\":  keras.applications.efficientnet.preprocess_input,\n",
    "    }\n",
    "    \n",
    "    inputs = keras.layers.Input(input_shape)\n",
    "    x = keras.layers.Rescaling(255.)(inputs) # To parse from [0, 1] to [0, 225]\n",
    "    x = PREPROCESS.get(backbone_name, lambda x: x / 255.0)(x)\n",
    "    \n",
    "    backbone = instantiate_backbone(backbone_name, weights=backbone_weights)\n",
    "    if backbone_weights:\n",
    "        backbone.trainable = False\n",
    "\n",
    "    x = backbone(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"global_pool\")(x)\n",
    "    x = keras.layers.Dropout(0.3, name=\"dropout\")(x)\n",
    "\n",
    "    for i, (nodes, use_batch_normalization, use_dropout) in enumerate(model_description[\"head_description\"]):\n",
    "        use_bias = not use_batch_normalization\n",
    "        \n",
    "        x = keras.layers.Dense(nodes, use_bias=use_bias, activation=\"linear\", name=f\"dense_{i}\")(x)\n",
    "\n",
    "        if use_batch_normalization:\n",
    "            x = keras.layers.BatchNormalization(name=f\"batchnorm_{i}\")(x)\n",
    "\n",
    "        x = keras.layers.ReLU(name=f\"relu_{i}\")(x)\n",
    "        \n",
    "        if use_dropout:\n",
    "            x = keras.layers.Dropout(0.3, name=f\"dropout_{i}\")(x)\n",
    "    \n",
    "    output_x = keras.layers.Dense(1, name=\"vel_x\")(x)\n",
    "    output_y = keras.layers.Dense(1, name=\"vel_y\")(x)\n",
    "\n",
    "    outputs = [output_x, output_y]\n",
    "\n",
    "    return keras.models.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        name=model_description[\"name\"]\n",
    "    ), backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f26cca2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.433605Z",
     "iopub.status.busy": "2025-06-28T23:55:28.433195Z",
     "iopub.status.idle": "2025-06-28T23:55:28.438629Z",
     "shell.execute_reply": "2025-06-28T23:55:28.437830Z"
    },
    "papermill": {
     "duration": 0.013189,
     "end_time": "2025-06-28T23:55:28.440092",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.426903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unfreeze_weights(backbone: keras.Model, from_layer: str, to_layer: str, unfreeze_bn=False):\n",
    "    unfreeze = False\n",
    "\n",
    "    for layer in backbone.layers:\n",
    "        if layer.name == from_layer:\n",
    "            unfreeze = True\n",
    "        \n",
    "        if unfreeze:\n",
    "            if isinstance(layer, keras.layers.BatchNormalization) and not unfreeze_bn:\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                layer.trainable = True\n",
    "        \n",
    "        if layer.name == to_layer:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e570a8",
   "metadata": {
    "_cell_guid": "8b949554-8397-47b4-8a63-78059a81c28b",
    "_uuid": "4d37cd51-11db-47f5-abc8-e1afaf6094a1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.451791Z",
     "iopub.status.busy": "2025-06-28T23:55:28.451390Z",
     "iopub.status.idle": "2025-06-28T23:55:28.457695Z",
     "shell.execute_reply": "2025-06-28T23:55:28.456923Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013794,
     "end_time": "2025-06-28T23:55:28.459010",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.445216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model: keras.Model, train_dataset: tf.data.Dataset, validation_dataset: tf.data.Dataset):\n",
    "    history_1 = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        verbose=0,\n",
    "        epochs=40,\n",
    "    )\n",
    "\n",
    "    history_2 = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=200,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=15,\n",
    "                min_delta=1e-4,\n",
    "                mode=\"min\",\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=5,\n",
    "                factor=0.5,\n",
    "                min_lr=1e-7,\n",
    "                mode=\"min\"\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    full_history = pd.concat([\n",
    "        pd.DataFrame(history_1.history),\n",
    "        pd.DataFrame(history_2.history),\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "    return model, full_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f707b67",
   "metadata": {
    "_cell_guid": "fbe70ec3-6d83-475a-a4e5-59147d8d1095",
    "_uuid": "1fb78ded-f93b-4599-b9e2-e74a8f2e2f69",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004876,
     "end_time": "2025-06-28T23:55:28.469047",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.464171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Results structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45d4831e",
   "metadata": {
    "_cell_guid": "0a1a1244-cd3e-421d-9e93-13a39069febc",
    "_uuid": "fed5480a-0b2a-4a84-9313-35a77e82c0ff",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.480206Z",
     "iopub.status.busy": "2025-06-28T23:55:28.479897Z",
     "iopub.status.idle": "2025-06-28T23:55:28.484556Z",
     "shell.execute_reply": "2025-06-28T23:55:28.483551Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012142,
     "end_time": "2025-06-28T23:55:28.486117",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.473975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_description in models_descriptions:\n",
    "    model_name = model_description[\"name\"]\n",
    "    \n",
    "    results[model_name] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c39582",
   "metadata": {
    "_cell_guid": "80e22271-2889-4906-9c77-4cb4d6a68af3",
    "_uuid": "d275ffdf-f5e1-410d-ba75-d689afd2f1ba",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004711,
     "end_time": "2025-06-28T23:55:28.495917",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.491206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Benchmark loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d32acfd",
   "metadata": {
    "_cell_guid": "f40bbf49-f336-4f04-9141-1c1faac5f8b5",
    "_kg_hide-output": true,
    "_uuid": "55ce7c7a-682c-42f0-a270-b2eb2a87d546",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-28T23:55:28.507243Z",
     "iopub.status.busy": "2025-06-28T23:55:28.506927Z",
     "iopub.status.idle": "2025-06-29T04:02:18.809991Z",
     "shell.execute_reply": "2025-06-29T04:02:18.808866Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 14810.310968,
     "end_time": "2025-06-29T04:02:18.811769",
     "exception": false,
     "start_time": "2025-06-28T23:55:28.500801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 23:55:28.555701: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model DroNet-500  for configuration (0.01, 32)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 438ms/step - loss: 1.8601 - vel_x_eva: 2.7592e-07 - vel_x_loss: 0.6339 - vel_x_r2_score: -0.0429 - vel_x_rmse: 0.7494 - vel_y_eva: 1.7057e-07 - vel_y_loss: 0.7614 - vel_y_r2_score: -0.0266 - vel_y_rmse: 0.8701\n",
      "Training model DroNet-600  for configuration (0.01, 32)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 5329.0024 - vel_x_eva: 2.5646e-07 - vel_x_loss: 0.6370 - vel_x_r2_score: -0.0486 - vel_x_rmse: 0.7513 - vel_y_eva: 2.0274e-07 - vel_y_loss: 0.7716 - vel_y_r2_score: -0.0378 - vel_y_rmse: 0.8753\n",
      "Training model DroNet-500  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 41.2411 - vel_x_eva: 2.4055e-07 - vel_x_loss: 0.5945 - vel_x_r2_score: -0.0377 - vel_x_rmse: 0.7575 - vel_y_eva: 1.6505e-07 - vel_y_loss: 0.7539 - vel_y_r2_score: -0.0118 - vel_y_rmse: 0.8666\n",
      "Training model DroNet-600  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 231.5776 - vel_x_eva: 1.7921e-07 - vel_x_loss: 0.5983 - vel_x_r2_score: -0.0468 - vel_x_rmse: 0.7603 - vel_y_eva: 1.6505e-07 - vel_y_loss: 0.7535 - vel_y_r2_score: -0.0116 - vel_y_rmse: 0.8664\n",
      "Training model DroNet-500  for configuration (0.01, 128)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - loss: 309.2617 - vel_x_eva: 1.9073e-07 - vel_x_loss: 0.5758 - vel_x_r2_score: -0.0263 - vel_x_rmse: 0.7581 - vel_y_eva: 1.5895e-07 - vel_y_loss: 0.7595 - vel_y_r2_score: -0.0047 - vel_y_rmse: 0.8706\n",
      "Training model DroNet-600  for configuration (0.01, 128)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - loss: 1623.8282 - vel_x_eva: 1.9073e-07 - vel_x_loss: 0.5713 - vel_x_r2_score: -0.0182 - vel_x_rmse: 0.7551 - vel_y_eva: 1.5895e-07 - vel_y_loss: 0.7598 - vel_y_r2_score: -0.0050 - vel_y_rmse: 0.8708\n",
      "Training model DroNet-500  for configuration (0.001, 32)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 1.4048 - vel_x_eva: 2.7504e-07 - vel_x_loss: 0.6310 - vel_x_r2_score: -0.0377 - vel_x_rmse: 0.7476 - vel_y_eva: 1.7057e-07 - vel_y_loss: 0.7660 - vel_y_r2_score: -0.0311 - vel_y_rmse: 0.8723\n",
      "Training model DroNet-600  for configuration (0.001, 32)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 1.3960 - vel_x_eva: 2.7751e-07 - vel_x_loss: 0.6305 - vel_x_r2_score: -0.0369 - vel_x_rmse: 0.7473 - vel_y_eva: 1.8318e-07 - vel_y_loss: 0.7615 - vel_y_r2_score: -0.0266 - vel_y_rmse: 0.8701\n",
      "Training model DroNet-500  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 1.3671 - vel_x_eva: 2.0589e-07 - vel_x_loss: 0.5897 - vel_x_r2_score: -0.0259 - vel_x_rmse: 0.7540 - vel_y_eva: 1.5836e-07 - vel_y_loss: 0.7544 - vel_y_r2_score: -0.0136 - vel_y_rmse: 0.8671\n",
      "Training model DroNet-600  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 1.3587 - vel_x_eva: 2.1306e-07 - vel_x_loss: 0.5862 - vel_x_r2_score: -0.0166 - vel_x_rmse: 0.7514 - vel_y_eva: 1.6505e-07 - vel_y_loss: 0.7539 - vel_y_r2_score: -0.0118 - vel_y_rmse: 0.8666\n",
      "Training model DroNet-500  for configuration (0.001, 128)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - loss: 1.3367 - vel_x_eva: 2.1060e-07 - vel_x_loss: 0.5614 - vel_x_r2_score: -4.0729e-04 - vel_x_rmse: 0.7485 - vel_y_eva: 1.5895e-07 - vel_y_loss: 0.7594 - vel_y_r2_score: -0.0047 - vel_y_rmse: 0.8706\n",
      "Training model DroNet-600  for configuration (0.001, 128)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - loss: 1.3367 - vel_x_eva: 2.1259e-07 - vel_x_loss: 0.5678 - vel_x_r2_score: -0.0120 - vel_x_rmse: 0.7528 - vel_y_eva: 1.5895e-07 - vel_y_loss: 0.7595 - vel_y_r2_score: -0.0048 - vel_y_rmse: 0.8707\n",
      "Training model DroNet-500  for configuration (0.0001, 32)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 1.2109 - vel_x_eva: -1.9270e-04 - vel_x_loss: 0.6234 - vel_x_r2_score: -0.0504 - vel_x_rmse: 0.7465 - vel_y_eva: 0.3506 - vel_y_loss: 0.5198 - vel_y_r2_score: 0.2825 - vel_y_rmse: 0.7170\n",
      "Training model DroNet-600  for configuration (0.0001, 32)\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 1.1986 - vel_x_eva: -0.0044 - vel_x_loss: 0.6352 - vel_x_r2_score: -0.0439 - vel_x_rmse: 0.7500 - vel_y_eva: 0.3041 - vel_y_loss: 0.5328 - vel_y_r2_score: 0.2732 - vel_y_rmse: 0.7271\n",
      "Training model DroNet-500  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 1.1460 - vel_x_eva: -0.0054 - vel_x_loss: 0.5990 - vel_x_r2_score: -0.0523 - vel_x_rmse: 0.7613 - vel_y_eva: 0.3598 - vel_y_loss: 0.4849 - vel_y_r2_score: 0.3538 - vel_y_rmse: 0.6932\n",
      "Training model DroNet-600  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.0463 - vel_x_eva: -0.0255 - vel_x_loss: 0.6072 - vel_x_r2_score: -0.0632 - vel_x_rmse: 0.7661 - vel_y_eva: 0.4681 - vel_y_loss: 0.3966 - vel_y_r2_score: 0.4614 - vel_y_rmse: 0.6253\n",
      "Training model DroNet-500  for configuration (0.0001, 128)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - loss: 1.0478 - vel_x_eva: 0.0620 - vel_x_loss: 0.5340 - vel_x_r2_score: 0.0469 - vel_x_rmse: 0.7302 - vel_y_eva: 0.4291 - vel_y_loss: 0.4367 - vel_y_r2_score: 0.4176 - vel_y_rmse: 0.6603\n",
      "Training model DroNet-600  for configuration (0.0001, 128)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - loss: 1.1508 - vel_x_eva: 0.0217 - vel_x_loss: 0.5715 - vel_x_r2_score: -0.0197 - vel_x_rmse: 0.7552 - vel_y_eva: 0.3426 - vel_y_loss: 0.5085 - vel_y_r2_score: 0.3250 - vel_y_rmse: 0.7126\n"
     ]
    }
   ],
   "source": [
    "samples_dataframe = load_samples_dataframe(\"/kaggle/input/marketplace-navigation-dataset/dataset\")\n",
    "# samples_dataframe = samples_dataframe.sample(frac=0.05)\n",
    "\n",
    "round_number = 1\n",
    "seed = round_number\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for model_description in models_descriptions:\n",
    "    dataset_key = tuple(model_description[\"input\"][\"shape\"])\n",
    "    dataset_key = model_description[\"input\"][\"grayscale\"], dataset_key\n",
    "    \n",
    "    if not dataset_key in datasets:\n",
    "        datasets[dataset_key] = build_train_val_test_datasets(\n",
    "            samples_dataframe,\n",
    "            model_description[\"input\"],\n",
    "            seed\n",
    "        )\n",
    "        \n",
    "for configuration in configurations:\n",
    "    for model_description in models_descriptions:\n",
    "        print(\"Training model\", model_description[\"name\"], \" for configuration\", configuration)\n",
    "        \n",
    "        learning_rate, batch_size = configuration\n",
    "        dataset_key = tuple(model_description[\"input\"][\"shape\"])\n",
    "        dataset_key = model_description[\"input\"][\"grayscale\"], dataset_key\n",
    "\n",
    "        train_ds = datasets[dataset_key][\"train\"]\n",
    "        val_ds   = datasets[dataset_key][\"val\"]\n",
    "        test_ds  = datasets[dataset_key][\"test\"]\n",
    "        \n",
    "        train_ds = train_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        val_ds   = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        test_ds  = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        model, backbone = build_model(model_description)\n",
    "        \n",
    "        model.compile(\n",
    "            loss={\n",
    "                \"vel_x\": \"mean_squared_error\",\n",
    "                \"vel_y\": \"mean_squared_error\",\n",
    "            },\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            metrics={\n",
    "                \"vel_x\": [rmse, eva, r2_score],\n",
    "                \"vel_y\": [rmse, eva, r2_score],\n",
    "            },\n",
    "        )\n",
    "        model, history_1 = train_model(model, train_ds, val_ds)\n",
    "\n",
    "        unfreeze_weights(backbone, \"add_2\", \"add_3\")\n",
    "        \n",
    "        model.compile(\n",
    "            loss={\n",
    "                \"vel_x\": \"mean_squared_error\",\n",
    "                \"vel_y\": \"mean_squared_error\",\n",
    "            },\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate / 1e-3),\n",
    "            metrics={\n",
    "                \"vel_x\": [rmse, eva, r2_score],\n",
    "                \"vel_y\": [rmse, eva, r2_score],\n",
    "            },\n",
    "        )\n",
    "        model, history_2 = train_model(model, train_ds, val_ds)\n",
    "\n",
    "        evaluation_metrics = model.evaluate(test_ds, return_dict=True)\n",
    "        \n",
    "        results[model_description[\"name\"]][configuration] = evaluation_metrics\n",
    "\n",
    "        file_name = f\"r{round_number}_{model.name}_{learning_rate:.0e}_{batch_size}\"\n",
    "\n",
    "        model.save(f\"{file_name}.keras\")\n",
    "        \n",
    "        pd.concat([\n",
    "            history_1,\n",
    "            history_2,\n",
    "        ]).reset_index(drop=True).to_csv(f\"{file_name}.csv\")\n",
    "        \n",
    "        with open(\"results.pkl\", \"wb\") as results_file:\n",
    "            pickle.dump(results, results_file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6187980,
     "sourceId": 10061785,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14838.722333,
   "end_time": "2025-06-29T04:02:22.554393",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-28T23:55:03.832060",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
