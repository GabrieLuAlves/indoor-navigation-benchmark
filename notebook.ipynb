{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fba3d4",
   "metadata": {
    "_cell_guid": "31cda6c9-1a82-4124-b805-116202195863",
    "_uuid": "80eb9cab-e2af-4b59-bb1d-c9da376c23fb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:42:59.486113Z",
     "iopub.status.busy": "2025-07-01T21:42:59.485832Z",
     "iopub.status.idle": "2025-07-01T21:43:14.787755Z",
     "shell.execute_reply": "2025-07-01T21:43:14.787151Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.309254,
     "end_time": "2025-07-01T21:43:14.789185",
     "exception": false,
     "start_time": "2025-07-01T21:42:59.479931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 21:43:03.705027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751406183.907805      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751406183.973068      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d6ad8",
   "metadata": {
    "_cell_guid": "eb6ae085-ac99-47ec-a0a2-5683f602486e",
    "_uuid": "ff3814a7-d691-41bc-b0f1-6da33c4a9ac2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003973,
     "end_time": "2025-07-01T21:43:14.797928",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.793955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ff7ff8",
   "metadata": {
    "_cell_guid": "2ff167d9-a16d-45f2-8326-5ddacc1e0035",
    "_uuid": "dbc1d7e6-369e-474e-867d-c88fc75a5eec",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.807228Z",
     "iopub.status.busy": "2025-07-01T21:43:14.806778Z",
     "iopub.status.idle": "2025-07-01T21:43:14.814685Z",
     "shell.execute_reply": "2025-07-01T21:43:14.813993Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013761,
     "end_time": "2025-07-01T21:43:14.815775",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.802014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "    \n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "@tf.function\n",
    "def eva(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "\n",
    "    numerator = tf.math.reduce_variance(y_true - y_pred)\n",
    "    denominator = tf.math.reduce_variance(y_true) + tf.keras.backend.epsilon()\n",
    "    \n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "@tf.function\n",
    "def r2_score(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "    \n",
    "    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    \n",
    "    return 1 - (ss_res / (ss_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11cb46",
   "metadata": {
    "_cell_guid": "47399b8c-5071-4124-9cbb-0b091cae6af5",
    "_uuid": "d2959917-ade9-410a-81b6-ea0d9f1efa35",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003826,
     "end_time": "2025-07-01T21:43:14.823612",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.819786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. ResNet 8/18/34 construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f3e439",
   "metadata": {
    "_cell_guid": "60c3f6be-a0f0-44b2-9ace-a203ae45387d",
    "_uuid": "6a63061c-9d12-4bf9-ad97-605fa393efe5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.832271Z",
     "iopub.status.busy": "2025-07-01T21:43:14.832060Z",
     "iopub.status.idle": "2025-07-01T21:43:14.836675Z",
     "shell.execute_reply": "2025-07-01T21:43:14.836081Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010084,
     "end_time": "2025-07-01T21:43:14.837823",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.827739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resnet_block(x, filters, stride=1, use_projection=False):\n",
    "    shortcut = x\n",
    "\n",
    "    x = keras.layers.Conv2D(filters, 3, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters, 3, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if use_projection:\n",
    "        shortcut = keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n",
    "        shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Add()([x, shortcut])\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce7adec",
   "metadata": {
    "_cell_guid": "36e1a4e9-a964-438b-82f8-e1f6b6a13fb7",
    "_uuid": "70aff8e4-29bd-4438-a3c0-fbfa0a441b21",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.846287Z",
     "iopub.status.busy": "2025-07-01T21:43:14.846076Z",
     "iopub.status.idle": "2025-07-01T21:43:14.850492Z",
     "shell.execute_reply": "2025-07-01T21:43:14.849999Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009848,
     "end_time": "2025-07-01T21:43:14.851565",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.841717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet8_DroNet(input_shape=(200, 200, 1), dropout_rate=0.3):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = keras.layers.Conv2D(32, 5, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    x = resnet_block(x, 32)\n",
    "    x = resnet_block(x, 32)\n",
    "\n",
    "    x = resnet_block(x, 64, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 128)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet8_DroNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31244cdd",
   "metadata": {
    "_cell_guid": "eb601a36-0827-4cd8-900a-1421fbb33180",
    "_uuid": "fd96d071-c11b-406b-8d54-16fdbe7920fa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.860438Z",
     "iopub.status.busy": "2025-07-01T21:43:14.859966Z",
     "iopub.status.idle": "2025-07-01T21:43:14.865009Z",
     "shell.execute_reply": "2025-07-01T21:43:14.864485Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010449,
     "end_time": "2025-07-01T21:43:14.866017",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.855568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet18(input_shape=(224, 224, 3)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Conv2_x\n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "    # Conv3_x\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 128)\n",
    "\n",
    "    # Conv4_x\n",
    "    x = resnet_block(x, 256, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 256)\n",
    "\n",
    "    # Conv5_x\n",
    "    x = resnet_block(x, 512, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 512)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet18_backbone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4aaef5d",
   "metadata": {
    "_cell_guid": "bf96671e-1e5a-4a52-8cda-acec12713328",
    "_uuid": "c7359e0e-6fd4-4e19-a903-f746ea3b2031",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.875048Z",
     "iopub.status.busy": "2025-07-01T21:43:14.874633Z",
     "iopub.status.idle": "2025-07-01T21:43:14.879910Z",
     "shell.execute_reply": "2025-07-01T21:43:14.879425Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010739,
     "end_time": "2025-07-01T21:43:14.880958",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.870219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet34(input_shape=(224, 224, 3)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Conv2_x (3 blocks)\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 64)\n",
    "\n",
    "    # Conv3_x (4 blocks)\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 128)\n",
    "\n",
    "    # Conv4_x (6 blocks)\n",
    "    x = resnet_block(x, 256, stride=2, use_projection=True)\n",
    "    for _ in range(5):\n",
    "        x = resnet_block(x, 256)\n",
    "\n",
    "    # Conv5_x (3 blocks)\n",
    "    x = resnet_block(x, 512, stride=2, use_projection=True)\n",
    "    for _ in range(2):\n",
    "        x = resnet_block(x, 512)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet34_backbone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ffe13b",
   "metadata": {
    "_cell_guid": "38dff14a-d86f-4e88-b050-acfe49c6a8ca",
    "_uuid": "e8131d1c-9673-4df0-8bdc-4056bff54c3d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003858,
     "end_time": "2025-07-01T21:43:14.889768",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.885910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Grid search configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01226df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.898782Z",
     "iopub.status.busy": "2025-07-01T21:43:14.898581Z",
     "iopub.status.idle": "2025-07-01T21:43:14.901938Z",
     "shell.execute_reply": "2025-07-01T21:43:14.901250Z"
    },
    "papermill": {
     "duration": 0.009488,
     "end_time": "2025-07-01T21:43:14.903161",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.893673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "configurations = list(product([0.0001, 0.001, 0.01], [64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d908c30",
   "metadata": {
    "_cell_guid": "39de600a-4622-43e0-8762-5bbc77aed4e1",
    "_uuid": "49029c5d-396b-406c-b077-8ba68255fd92",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003682,
     "end_time": "2025-07-01T21:43:14.911297",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.907615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a04bf7de",
   "metadata": {
    "_cell_guid": "6ac38ad7-4355-4733-8478-1c68d1231670",
    "_uuid": "82faa4c8-711e-4663-bc08-d36895955d3f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.920089Z",
     "iopub.status.busy": "2025-07-01T21:43:14.919899Z",
     "iopub.status.idle": "2025-07-01T21:43:14.927969Z",
     "shell.execute_reply": "2025-07-01T21:43:14.927499Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013787,
     "end_time": "2025-07-01T21:43:14.928993",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.915206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_descriptions = [\n",
    "    {\n",
    "        \"name\": \"ResNet-8-base\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-8\"\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [200, 200, 1],\n",
    "            \"grayscale\": True,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ResNet-8-600A\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-8\"\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [200, 200, 1],\n",
    "            \"grayscale\": True,\n",
    "        },\n",
    "        \"head_description\": [\n",
    "            (64, False, None),\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ResNet-8-600B\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-8\"\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [200, 200, 1],\n",
    "            \"grayscale\": True,\n",
    "        },\n",
    "        \"head_description\": [\n",
    "            (64, True, None),\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ResNet-18\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-18\",\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ResNet-34\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-34\",\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ResNet-50\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-50\",\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ResNet-50V2\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"ResNet-50V2\",\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MobileNet\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"MobileNet\",\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"EfficientNetB0\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"EfficientNetB0\",\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Format verification\n",
    "for model_description in models_descriptions:\n",
    "    if \"backbone\" not in model_description:\n",
    "        raise KeyError(\"backbone not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"name\" not in model_description[\"backbone\"]:\n",
    "        raise KeyError(\"backbone.name not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"weights\" not in model_description[\"backbone\"]:\n",
    "        model_description[\"backbone\"][\"weights\"] = None\n",
    "    \n",
    "    if \"name\" not in model_description:\n",
    "        model_description[\"name\"] = model_description[\"backbone\"][\"name\"]\n",
    "\n",
    "    if \"head_description\" not in model_description:\n",
    "        model_description[\"head_description\"] = []\n",
    "\n",
    "    if \"weights\" not in model_description:\n",
    "        model_description[\"weights\"] = None\n",
    "\n",
    "    if \"input\" not in model_description:\n",
    "        raise KeyError(\"input not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"shape\" not in model_description[\"input\"]:\n",
    "        raise KeyError(\"input.shape not specified at:\\n\" + str(model_description))\n",
    "    \n",
    "    if \"grayscale\" not in model_description[\"input\"]:\n",
    "        model_description[\"input\"][\"grayscale\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b9bf1",
   "metadata": {
    "papermill": {
     "duration": 0.003711,
     "end_time": "2025-07-01T21:43:14.936734",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.933023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load dataset and build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7529e03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.945507Z",
     "iopub.status.busy": "2025-07-01T21:43:14.945059Z",
     "iopub.status.idle": "2025-07-01T21:43:14.949080Z",
     "shell.execute_reply": "2025-07-01T21:43:14.948560Z"
    },
    "papermill": {
     "duration": 0.009391,
     "end_time": "2025-07-01T21:43:14.950012",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.940621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_samples_dataframe(path: str):\n",
    "    images_folder = os.path.join(path, \"images\")\n",
    "\n",
    "    samples_df = pd.read_csv(\n",
    "        os.path.join(path, \"market_dataset_xy.txt\"),\n",
    "        sep=\" \",\n",
    "        header=None,\n",
    "        names=[\"file path\", \"_\", \"datetime\", \"vel_y\", \"vel_x\"]\n",
    "    )\n",
    "\n",
    "    samples_df[\"file path\"] = (\n",
    "        samples_df[\"file path\"]\n",
    "        .apply(lambda image_name: os.path.join(path, \"images\", image_name))\n",
    "    )\n",
    "    \n",
    "    return samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a2808b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.959101Z",
     "iopub.status.busy": "2025-07-01T21:43:14.958740Z",
     "iopub.status.idle": "2025-07-01T21:43:14.963806Z",
     "shell.execute_reply": "2025-07-01T21:43:14.963267Z"
    },
    "papermill": {
     "duration": 0.010543,
     "end_time": "2025-07-01T21:43:14.964816",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.954273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def augment(image, label):\n",
    "    # Brightness and contrast\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    \n",
    "    # Flip horizontally\n",
    "    do_flip = tf.random.uniform([]) > 0.5\n",
    "    image = tf.cond(do_flip, lambda: tf.image.flip_left_right(image), lambda: image)\n",
    "    \n",
    "    vel_x = tf.cond(do_flip, lambda: -label[\"vel_x\"], lambda: label[\"vel_x\"])\n",
    "    vel_y = label[\"vel_y\"]\n",
    "    \n",
    "    # Optionally add noise\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.025)\n",
    "    image = image + noise\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    return image, {\"vel_x\": vel_x, \"vel_y\": vel_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7cc6f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.973309Z",
     "iopub.status.busy": "2025-07-01T21:43:14.972964Z",
     "iopub.status.idle": "2025-07-01T21:43:14.977149Z",
     "shell.execute_reply": "2025-07-01T21:43:14.976625Z"
    },
    "papermill": {
     "duration": 0.009392,
     "end_time": "2025-07-01T21:43:14.978136",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.968744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(path, mode=\"color\"):\n",
    "    image = tf.io.read_file(path)\n",
    "\n",
    "    if mode == \"color\":\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    elif mode == \"grayscale1\":\n",
    "        image = tf.image.decode_jpeg(image, channels=1)\n",
    "\n",
    "    elif mode == \"grayscale3\":\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db65e8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:14.986750Z",
     "iopub.status.busy": "2025-07-01T21:43:14.986297Z",
     "iopub.status.idle": "2025-07-01T21:43:14.993502Z",
     "shell.execute_reply": "2025-07-01T21:43:14.992819Z"
    },
    "papermill": {
     "duration": 0.012604,
     "end_time": "2025-07-01T21:43:14.994612",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.982008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_train_val_test_datasets(samples_dataframe, input_description: dict, seed=42):\n",
    "    # Split\n",
    "    df_train, df_temp = train_test_split(samples_dataframe, test_size=0.4, random_state=seed)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=seed)\n",
    "\n",
    "    resolution = input_description[\"shape\"][:2]\n",
    "    channels = input_description[\"shape\"][2]\n",
    "\n",
    "    if channels == 1:\n",
    "        mode = \"grayscale1\"\n",
    "    elif input_description[\"grayscale\"] and channels == 3:\n",
    "        mode = \"grayscale3\"\n",
    "    else:\n",
    "        mode = \"color\"\n",
    "\n",
    "    print(\"Created\", mode, \"dataset with resolution\", resolution)\n",
    "\n",
    "    def process_sample(path, label):\n",
    "        image = load_image(path, mode=mode)\n",
    "        image = tf.image.resize(image, resolution)\n",
    "        image.set_shape(input_description[\"shape\"])\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def df_to_tf_dataset(df, training=False):\n",
    "        paths = tf.constant(df[\"file path\"].tolist())\n",
    "        vel_x = tf.constant(df[\"vel_x\"].astype(\"float32\").tolist())\n",
    "        vel_y = tf.constant(df[\"vel_y\"].astype(\"float32\").tolist())\n",
    "    \n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, {\"vel_x\": vel_x, \"vel_y\": vel_y}))\n",
    "    \n",
    "        ds = ds.map(process_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.cache()\n",
    "    \n",
    "        if training:\n",
    "            ds = ds.shuffle(len(df), reshuffle_each_iteration=True)\n",
    "            ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            \n",
    "        return ds\n",
    "\n",
    "    return {\n",
    "        \"train\": df_to_tf_dataset(df_train, training=True),\n",
    "        \"val\":   df_to_tf_dataset(df_val, training=False),\n",
    "        \"test\":  df_to_tf_dataset(df_test, training=False),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90a0a116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:15.003556Z",
     "iopub.status.busy": "2025-07-01T21:43:15.002974Z",
     "iopub.status.idle": "2025-07-01T21:43:15.010538Z",
     "shell.execute_reply": "2025-07-01T21:43:15.010043Z"
    },
    "papermill": {
     "duration": 0.01293,
     "end_time": "2025-07-01T21:43:15.011556",
     "exception": false,
     "start_time": "2025-07-01T21:43:14.998626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def instantiate_backbone(backbone_name, weights=None):\n",
    "    if backbone_name == \"ResNet-8\":\n",
    "        if weights is not None:\n",
    "            print(\"[INFO] No pre-trained weights available for ResNet-8\")\n",
    "        return ResNet8_DroNet(input_shape=(200, 200, 1))\n",
    "\n",
    "    if backbone_name == \"ResNet-18\":\n",
    "        if weights is not None:\n",
    "            print(\"[INFO] No pre-trained weights available for ResNet-18\")\n",
    "        return ResNet18(input_shape=(224, 224, 3))\n",
    "\n",
    "    if backbone_name == \"ResNet-34\":\n",
    "        if weights is not None:\n",
    "            print(\"[INFO] No pre-trained weights available for ResNet-34\")\n",
    "        return ResNet34(input_shape=(224, 224, 3))\n",
    "\n",
    "    if backbone_name == \"ResNet-50\":\n",
    "        assert not weights or weights in [\"imagenet\"], f\"[ERROR] no {weights} weights found for ResNet-50\"\n",
    "        return keras.applications.ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\" if weights == \"imagenet\" else None,\n",
    "            pooling=None,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"ResNet-50V2\":\n",
    "        assert not weights or weights in [\"imagenet\"], f\"[ERROR] no {weights} weights found for ResNet-50V2\"\n",
    "        return keras.applications.ResNet50V2(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\" if weights == \"imagenet\" else None,\n",
    "            pooling=None,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"MobileNet\":\n",
    "        assert not weights or weights in [\"imagenet\"], f\"[ERROR] no {weights} weights found for MobileNet\"\n",
    "        return keras.applications.MobileNet(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\" if weights == \"imagenet\" else None,\n",
    "            pooling=None,\n",
    "            alpha=1.0,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"MobileNetV2\":\n",
    "        assert not weights or weights in [\"imagenet\"], f\"[ERROR] no {weights} weights found for MobileNetV2\"\n",
    "        return keras.applications.MobileNetV2(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\" if weights == \"imagenet\" else None,\n",
    "            pooling=None,\n",
    "            alpha=1.0,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"EfficientNetB0\":\n",
    "        assert not weights or weights in [\"imagenet\"], f\"[ERROR] no {weights} weights found for EfficientNetB0\"\n",
    "        return keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\" if weights == \"imagenet\" else None,\n",
    "            pooling=None,\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Backbone {backbone_name} not implemented.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9a16e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:15.019989Z",
     "iopub.status.busy": "2025-07-01T21:43:15.019781Z",
     "iopub.status.idle": "2025-07-01T21:43:15.026186Z",
     "shell.execute_reply": "2025-07-01T21:43:15.025705Z"
    },
    "papermill": {
     "duration": 0.011776,
     "end_time": "2025-07-01T21:43:15.027173",
     "exception": false,
     "start_time": "2025-07-01T21:43:15.015397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(model_description: dict):\n",
    "    input_shape = model_description[\"input\"][\"shape\"]\n",
    "    input_shape = tuple(input_shape)\n",
    "\n",
    "    backbone_name = model_description[\"backbone\"][\"name\"]\n",
    "    backbone_weights = model_description[\"backbone\"][\"weights\"]\n",
    "\n",
    "    PREPROCESS = {\n",
    "        \"MobileNet\":       keras.applications.mobilenet.preprocess_input,\n",
    "        \"MobileNetV2\":     keras.applications.mobilenet_v2.preprocess_input,\n",
    "        \"ResNet-50\":       keras.applications.resnet.preprocess_input,\n",
    "        \"ResNet-50V2\":     keras.applications.resnet_v2.preprocess_input,\n",
    "        \"EfficientNetB0\":  keras.applications.efficientnet.preprocess_input,\n",
    "    }\n",
    "    \n",
    "    inputs = keras.layers.Input(input_shape)\n",
    "    x = keras.layers.Rescaling(255.)(inputs) # To parse from [0, 1] to [0, 225]\n",
    "    x = PREPROCESS.get(backbone_name, lambda x: x / 255.0)(x)\n",
    "\n",
    "    backbone = instantiate_backbone(backbone_name, weights=backbone_weights)\n",
    "    if backbone_weights:\n",
    "        backbone.trainable = False\n",
    "\n",
    "    x = backbone(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D(name=\"global_pool\")(x)\n",
    "\n",
    "    for i, (nodes, use_batch_normalization, dropout_rate) in enumerate(model_description[\"head_description\"]):\n",
    "        use_bias = not use_batch_normalization\n",
    "        \n",
    "        x = keras.layers.Dense(nodes, use_bias=use_bias, activation=\"linear\", name=f\"dense_{i}\")(x)\n",
    "\n",
    "        if use_batch_normalization:\n",
    "            x = keras.layers.BatchNormalization(name=f\"batchnorm_{i}\")(x)\n",
    "\n",
    "        x = keras.layers.ReLU(name=f\"relu_{i}\")(x)\n",
    "        \n",
    "        if dropout_rate:\n",
    "            x = keras.layers.Dropout(dropout_rate, name=f\"dropout_{i}\")(x)\n",
    "    \n",
    "    output_x = keras.layers.Dense(1, name=\"vel_x\")(x)\n",
    "    output_y = keras.layers.Dense(1, name=\"vel_y\")(x)\n",
    "\n",
    "    outputs = [output_x, output_y]\n",
    "\n",
    "    return keras.models.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        name=model_description[\"name\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c63b32b8",
   "metadata": {
    "_cell_guid": "81fd146c-569e-41cd-a3b0-3697be73f389",
    "_uuid": "bf0dc136-a787-4acb-8200-a681d2426b5e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:15.035703Z",
     "iopub.status.busy": "2025-07-01T21:43:15.035510Z",
     "iopub.status.idle": "2025-07-01T21:43:15.039945Z",
     "shell.execute_reply": "2025-07-01T21:43:15.039486Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009819,
     "end_time": "2025-07-01T21:43:15.040885",
     "exception": false,
     "start_time": "2025-07-01T21:43:15.031066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model: keras.Model, train_dataset: tf.data.Dataset, validation_dataset: tf.data.Dataset):\n",
    "    history_1 = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        verbose=0,\n",
    "        epochs=40,\n",
    "    )\n",
    "\n",
    "    history_2 = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=200,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=45,\n",
    "                min_delta=1e-4,\n",
    "                mode=\"min\",\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=15,\n",
    "                factor=0.5,\n",
    "                min_lr=1e-7,\n",
    "                mode=\"min\"\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    full_history = pd.concat([\n",
    "        pd.DataFrame(history_1.history),\n",
    "        pd.DataFrame(history_2.history),\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "    return model, full_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459ca36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:15.049860Z",
     "iopub.status.busy": "2025-07-01T21:43:15.049299Z",
     "iopub.status.idle": "2025-07-01T21:43:15.054512Z",
     "shell.execute_reply": "2025-07-01T21:43:15.053838Z"
    },
    "papermill": {
     "duration": 0.010753,
     "end_time": "2025-07-01T21:43:15.055532",
     "exception": false,
     "start_time": "2025-07-01T21:43:15.044779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_labels_from_dataset(dataset: tf.data.Dataset, file_path: str):\n",
    "    labels_list = []\n",
    "\n",
    "    for _, label in dataset:\n",
    "        label_np = {key: val.numpy().item() for key, val in label.items()}\n",
    "        labels_list.append(label_np)\n",
    "\n",
    "    df = pd.DataFrame(labels_list)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Labels saved to {file_path}\")\n",
    "\n",
    "\n",
    "def save_predictions(predictions, file_path: str):\n",
    "    if isinstance(predictions, (list, tuple)):\n",
    "        # Example: [vel_x_array, vel_y_array]\n",
    "        pred_dict = {f\"vel_x\": predictions[0].flatten(),\n",
    "                     f\"vel_y\": predictions[1].flatten()}\n",
    "    else:\n",
    "        pred_dict = {key: val.flatten() for key, val in predictions.items()}\n",
    "\n",
    "    df = pd.DataFrame(pred_dict)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Predictions saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4410e5",
   "metadata": {
    "_cell_guid": "9bf3c32a-54e8-4151-bf50-0267a409748b",
    "_uuid": "6205940e-1262-4bad-a068-6b504c107336",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003644,
     "end_time": "2025-07-01T21:43:15.063133",
     "exception": false,
     "start_time": "2025-07-01T21:43:15.059489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Results structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "443319aa",
   "metadata": {
    "_cell_guid": "23d3c588-6bcc-4795-a80d-28372af0cbb0",
    "_uuid": "11c3b8a3-a8dc-47fb-90a4-cd088fa4e1d6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:15.071883Z",
     "iopub.status.busy": "2025-07-01T21:43:15.071676Z",
     "iopub.status.idle": "2025-07-01T21:43:15.075010Z",
     "shell.execute_reply": "2025-07-01T21:43:15.074327Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008794,
     "end_time": "2025-07-01T21:43:15.076096",
     "exception": false,
     "start_time": "2025-07-01T21:43:15.067302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_description in models_descriptions:\n",
    "    model_name = model_description[\"name\"]\n",
    "    \n",
    "    results[model_name] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e340af39",
   "metadata": {
    "papermill": {
     "duration": 0.003746,
     "end_time": "2025-07-01T21:43:15.083862",
     "exception": false,
     "start_time": "2025-07-01T21:43:15.080116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Benchmark loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed0393ae",
   "metadata": {
    "_cell_guid": "e152cd73-944e-4b15-aa4d-0ff037039760",
    "_kg_hide-output": true,
    "_uuid": "2d42d04f-46cf-475a-b7d4-2510a00f24ba",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T21:43:15.092873Z",
     "iopub.status.busy": "2025-07-01T21:43:15.092641Z",
     "iopub.status.idle": "2025-07-02T04:04:10.874791Z",
     "shell.execute_reply": "2025-07-02T04:04:10.874122Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 22855.788382,
     "end_time": "2025-07-02T04:04:10.876319",
     "exception": false,
     "start_time": "2025-07-01T21:43:15.087937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grayscale1 dataset with resolution [200, 200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751406196.273818      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels saved to r1_y_true.csv\n",
      "Created color dataset with resolution [224, 224]\n",
      "Labels saved to r1_y_true.csv\n",
      "Training model ResNet-8-base  for configuration (0.0001, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751406244.935556      59 service.cc:148] XLA service 0x7f22e00016b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751406244.936432      59 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1751406246.150911      59 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1751406253.908632      59 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1812 - vel_x_eva: 0.7037 - vel_x_loss: 0.1279 - vel_x_r2_score: 0.6967 - vel_x_rmse: 0.3537 - vel_y_eva: 0.9374 - vel_y_loss: 0.0538 - vel_y_r2_score: 0.9344 - vel_y_rmse: 0.2305\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step\n",
      "Predictions saved to r1_ResNet-8-base_1e-04_64_predictions.csv\n",
      "Training model ResNet-8-600A  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1696 - vel_x_eva: 0.7341 - vel_x_loss: 0.1177 - vel_x_r2_score: 0.7276 - vel_x_rmse: 0.3381 - vel_y_eva: 0.9408 - vel_y_loss: 0.0498 - vel_y_r2_score: 0.9397 - vel_y_rmse: 0.2222\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step\n",
      "Predictions saved to r1_ResNet-8-600A_1e-04_64_predictions.csv\n",
      "Training model ResNet-8-600B  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1483 - vel_x_eva: 0.7690 - vel_x_loss: 0.1000 - vel_x_r2_score: 0.7597 - vel_x_rmse: 0.3132 - vel_y_eva: 0.9421 - vel_y_loss: 0.0475 - vel_y_r2_score: 0.9415 - vel_y_rmse: 0.2164\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step\n",
      "Predictions saved to r1_ResNet-8-600B_1e-04_64_predictions.csv\n",
      "Training model ResNet-18  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1085 - vel_x_eva: 0.8213 - vel_x_loss: 0.0780 - vel_x_r2_score: 0.8115 - vel_x_rmse: 0.2774 - vel_y_eva: 0.9641 - vel_y_loss: 0.0311 - vel_y_r2_score: 0.9623 - vel_y_rmse: 0.1758\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 283ms/step\n",
      "Predictions saved to r1_ResNet-18_1e-04_64_predictions.csv\n",
      "Training model ResNet-34  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0613 - vel_x_eva: 0.8808 - vel_x_loss: 0.0487 - vel_x_r2_score: 0.8761 - vel_x_rmse: 0.2151 - vel_y_eva: 0.9845 - vel_y_loss: 0.0128 - vel_y_r2_score: 0.9844 - vel_y_rmse: 0.1131\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 364ms/step\n",
      "Predictions saved to r1_ResNet-34_1e-04_64_predictions.csv\n",
      "Training model ResNet-50  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0585 - vel_x_eva: 0.8931 - vel_x_loss: 0.0437 - vel_x_r2_score: 0.8877 - vel_x_rmse: 0.2034 - vel_y_eva: 0.9826 - vel_y_loss: 0.0155 - vel_y_r2_score: 0.9813 - vel_y_rmse: 0.1241\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 852ms/step\n",
      "Predictions saved to r1_ResNet-50_1e-04_64_predictions.csv\n",
      "Training model ResNet-50V2  for configuration (0.0001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0825 - vel_x_eva: 0.8520 - vel_x_loss: 0.0627 - vel_x_r2_score: 0.8449 - vel_x_rmse: 0.2462 - vel_y_eva: 0.9774 - vel_y_loss: 0.0192 - vel_y_r2_score: 0.9765 - vel_y_rmse: 0.1380\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 601ms/step\n",
      "Predictions saved to r1_ResNet-50V2_1e-04_64_predictions.csv\n",
      "Training model MobileNet  for configuration (0.0001, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1751412678.400946      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751412678.603056      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751412690.334837      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751412690.537256      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4307 - vel_x_eva: 0.4251 - vel_x_loss: 0.2464 - vel_x_r2_score: 0.4127 - vel_x_rmse: 0.4926 - vel_y_eva: 0.7785 - vel_y_loss: 0.1831 - vel_y_r2_score: 0.7781 - vel_y_rmse: 0.4274\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step\n",
      "Predictions saved to r1_MobileNet_1e-04_64_predictions.csv\n",
      "Training model EfficientNetB0  for configuration (0.0001, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1751413475.816088      58 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413476.009660      58 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413476.565040      58 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413476.772915      58 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413477.168323      58 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413477.376695      58 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413511.308434      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413511.494090      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413511.941426      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413512.150671      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413512.506536      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751413512.715970      57 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1824 - vel_x_eva: 0.7465 - vel_x_loss: 0.1001 - vel_x_r2_score: 0.7335 - vel_x_rmse: 0.3088 - vel_y_eva: 0.9148 - vel_y_loss: 0.0856 - vel_y_r2_score: 0.8958 - vel_y_rmse: 0.2908\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 956ms/step\n",
      "Predictions saved to r1_EfficientNetB0_1e-04_64_predictions.csv\n",
      "Training model ResNet-8-base  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1264 - vel_x_eva: 0.7872 - vel_x_loss: 0.0974 - vel_x_r2_score: 0.7838 - vel_x_rmse: 0.3062 - vel_y_eva: 0.9680 - vel_y_loss: 0.0273 - vel_y_r2_score: 0.9669 - vel_y_rmse: 0.1640\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step\n",
      "Predictions saved to r1_ResNet-8-base_1e-03_64_predictions.csv\n",
      "Training model ResNet-8-600A  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0807 - vel_x_eva: 0.8504 - vel_x_loss: 0.0663 - vel_x_r2_score: 0.8346 - vel_x_rmse: 0.2530 - vel_y_eva: 0.9827 - vel_y_loss: 0.0147 - vel_y_r2_score: 0.9825 - vel_y_rmse: 0.1200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step\n",
      "Predictions saved to r1_ResNet-8-600A_1e-03_64_predictions.csv\n",
      "Training model ResNet-8-600B  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0923 - vel_x_eva: 0.8294 - vel_x_loss: 0.0707 - vel_x_r2_score: 0.8268 - vel_x_rmse: 0.2598 - vel_y_eva: 0.9751 - vel_y_loss: 0.0206 - vel_y_r2_score: 0.9748 - vel_y_rmse: 0.1432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step\n",
      "Predictions saved to r1_ResNet-8-600B_1e-03_64_predictions.csv\n",
      "Training model ResNet-18  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0579 - vel_x_eva: 0.8785 - vel_x_loss: 0.0475 - vel_x_r2_score: 0.8771 - vel_x_rmse: 0.2099 - vel_y_eva: 0.9883 - vel_y_loss: 0.0097 - vel_y_r2_score: 0.9881 - vel_y_rmse: 0.0979\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 482ms/step\n",
      "Predictions saved to r1_ResNet-18_1e-03_64_predictions.csv\n",
      "Training model ResNet-34  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0517 - vel_x_eva: 0.8926 - vel_x_loss: 0.0415 - vel_x_r2_score: 0.8897 - vel_x_rmse: 0.1926 - vel_y_eva: 0.9885 - vel_y_loss: 0.0099 - vel_y_r2_score: 0.9880 - vel_y_rmse: 0.0988\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 327ms/step\n",
      "Predictions saved to r1_ResNet-34_1e-03_64_predictions.csv\n",
      "Training model ResNet-50  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0601 - vel_x_eva: 0.8717 - vel_x_loss: 0.0497 - vel_x_r2_score: 0.8696 - vel_x_rmse: 0.2157 - vel_y_eva: 0.9885 - vel_y_loss: 0.0097 - vel_y_r2_score: 0.9883 - vel_y_rmse: 0.0980\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 640ms/step\n",
      "Predictions saved to r1_ResNet-50_1e-03_64_predictions.csv\n",
      "Training model ResNet-50V2  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0733 - vel_x_eva: 0.8554 - vel_x_loss: 0.0578 - vel_x_r2_score: 0.8522 - vel_x_rmse: 0.2336 - vel_y_eva: 0.9830 - vel_y_loss: 0.0143 - vel_y_r2_score: 0.9826 - vel_y_rmse: 0.1183\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 548ms/step\n",
      "Predictions saved to r1_ResNet-50V2_1e-03_64_predictions.csv\n",
      "Training model MobileNet  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0578 - vel_x_eva: 0.8757 - vel_x_loss: 0.0479 - vel_x_r2_score: 0.8729 - vel_x_rmse: 0.2083 - vel_y_eva: 0.9889 - vel_y_loss: 0.0096 - vel_y_r2_score: 0.9883 - vel_y_rmse: 0.0975\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step\n",
      "Predictions saved to r1_MobileNet_1e-03_64_predictions.csv\n",
      "Training model EfficientNetB0  for configuration (0.001, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0759 - vel_x_eva: 0.8497 - vel_x_loss: 0.0557 - vel_x_r2_score: 0.8408 - vel_x_rmse: 0.2172 - vel_y_eva: 0.9764 - vel_y_loss: 0.0203 - vel_y_r2_score: 0.9752 - vel_y_rmse: 0.1399\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 910ms/step\n",
      "Predictions saved to r1_EfficientNetB0_1e-03_64_predictions.csv\n",
      "Training model ResNet-8-base  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0680 - vel_x_eva: 0.8690 - vel_x_loss: 0.0562 - vel_x_r2_score: 0.8620 - vel_x_rmse: 0.2279 - vel_y_eva: 0.9861 - vel_y_loss: 0.0116 - vel_y_r2_score: 0.9860 - vel_y_rmse: 0.1069\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step\n",
      "Predictions saved to r1_ResNet-8-base_1e-02_64_predictions.csv\n",
      "Training model ResNet-8-600A  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0734 - vel_x_eva: 0.8628 - vel_x_loss: 0.0574 - vel_x_r2_score: 0.8598 - vel_x_rmse: 0.2332 - vel_y_eva: 0.9824 - vel_y_loss: 0.0150 - vel_y_r2_score: 0.9816 - vel_y_rmse: 0.1207\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step\n",
      "Predictions saved to r1_ResNet-8-600A_1e-02_64_predictions.csv\n",
      "Training model ResNet-8-600B  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0593 - vel_x_eva: 0.8870 - vel_x_loss: 0.0472 - vel_x_r2_score: 0.8788 - vel_x_rmse: 0.2090 - vel_y_eva: 0.9861 - vel_y_loss: 0.0116 - vel_y_r2_score: 0.9860 - vel_y_rmse: 0.1069\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step\n",
      "Predictions saved to r1_ResNet-8-600B_1e-02_64_predictions.csv\n",
      "Training model ResNet-18  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0537 - vel_x_eva: 0.8857 - vel_x_loss: 0.0446 - vel_x_r2_score: 0.8827 - vel_x_rmse: 0.2033 - vel_y_eva: 0.9894 - vel_y_loss: 0.0089 - vel_y_r2_score: 0.9892 - vel_y_rmse: 0.0930\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step\n",
      "Predictions saved to r1_ResNet-18_1e-02_64_predictions.csv\n",
      "Training model ResNet-34  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0378 - vel_x_eva: 0.9280 - vel_x_loss: 0.0295 - vel_x_r2_score: 0.9235 - vel_x_rmse: 0.1591 - vel_y_eva: 0.9896 - vel_y_loss: 0.0097 - vel_y_r2_score: 0.9881 - vel_y_rmse: 0.0982\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 324ms/step\n",
      "Predictions saved to r1_ResNet-34_1e-02_64_predictions.csv\n",
      "Training model ResNet-50  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0810 - vel_x_eva: 0.8503 - vel_x_loss: 0.0641 - vel_x_r2_score: 0.8404 - vel_x_rmse: 0.2502 - vel_y_eva: 0.9793 - vel_y_loss: 0.0176 - vel_y_r2_score: 0.9785 - vel_y_rmse: 0.1319\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 625ms/step\n",
      "Predictions saved to r1_ResNet-50_1e-02_64_predictions.csv\n",
      "Training model ResNet-50V2  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0733 - vel_x_eva: 0.8486 - vel_x_loss: 0.0594 - vel_x_r2_score: 0.8469 - vel_x_rmse: 0.2369 - vel_y_eva: 0.9852 - vel_y_loss: 0.0126 - vel_y_r2_score: 0.9848 - vel_y_rmse: 0.1111\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 599ms/step\n",
      "Predictions saved to r1_ResNet-50V2_1e-02_64_predictions.csv\n",
      "Training model MobileNet  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0640 - vel_x_eva: 0.8510 - vel_x_loss: 0.0553 - vel_x_r2_score: 0.8496 - vel_x_rmse: 0.2190 - vel_y_eva: 0.9906 - vel_y_loss: 0.0079 - vel_y_r2_score: 0.9905 - vel_y_rmse: 0.0881\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 300ms/step\n",
      "Predictions saved to r1_MobileNet_1e-02_64_predictions.csv\n",
      "Training model EfficientNetB0  for configuration (0.01, 64)\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0580 - vel_x_eva: 0.8886 - vel_x_loss: 0.0433 - vel_x_r2_score: 0.8846 - vel_x_rmse: 0.1934 - vel_y_eva: 0.9833 - vel_y_loss: 0.0146 - vel_y_r2_score: 0.9821 - vel_y_rmse: 0.1204\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step\n",
      "Predictions saved to r1_EfficientNetB0_1e-02_64_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "samples_dataframe = load_samples_dataframe(\"/kaggle/input/marketplace-navigation-dataset/dataset\")\n",
    "# samples_dataframe = samples_dataframe.sample(frac=0.05)\n",
    "\n",
    "round_number = 1\n",
    "seed = round_number + 1\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for model_description in models_descriptions:\n",
    "    dataset_key = tuple(model_description[\"input\"][\"shape\"])\n",
    "    dataset_key = model_description[\"input\"][\"grayscale\"], dataset_key\n",
    "    \n",
    "    if not dataset_key in datasets:\n",
    "        datasets[dataset_key] = build_train_val_test_datasets(\n",
    "            samples_dataframe,\n",
    "            model_description[\"input\"],\n",
    "            seed\n",
    "        )\n",
    "        \n",
    "        save_labels_from_dataset(datasets[dataset_key][\"test\"], f\"r{round_number}_y_true.csv\")\n",
    "        \n",
    "for configuration in configurations:\n",
    "    for model_description in models_descriptions:\n",
    "        print(\"Training model\", model_description[\"name\"], \" for configuration\", configuration)\n",
    "        \n",
    "        learning_rate, batch_size = configuration\n",
    "        dataset_key = tuple(model_description[\"input\"][\"shape\"])\n",
    "        dataset_key = model_description[\"input\"][\"grayscale\"], dataset_key\n",
    "\n",
    "        train_ds = datasets[dataset_key][\"train\"]\n",
    "        val_ds   = datasets[dataset_key][\"val\"]\n",
    "        test_ds  = datasets[dataset_key][\"test\"]\n",
    "        \n",
    "        train_ds = train_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        val_ds   = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        test_ds  = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        model = build_model(model_description)\n",
    "        model.compile(\n",
    "            loss={\n",
    "                \"vel_x\": \"mean_squared_error\",\n",
    "                \"vel_y\": \"mean_squared_error\",\n",
    "            },\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            metrics={\n",
    "                \"vel_x\": [rmse, eva, r2_score],\n",
    "                \"vel_y\": [rmse, eva, r2_score],\n",
    "            },\n",
    "        )\n",
    "        model, history = train_model(model, train_ds, val_ds)\n",
    "\n",
    "        # Evaluate model\n",
    "        evaluation_metrics = model.evaluate(test_ds, return_dict=True)\n",
    "        \n",
    "        # Save predictions\n",
    "        predictions = model.predict(test_ds)\n",
    "        save_predictions(predictions, f\"r{round_number}_{model.name}_{learning_rate:.0e}_{batch_size}_predictions.csv\")\n",
    "\n",
    "        # Store metrics in results dict\n",
    "        results[model_description[\"name\"]][configuration] = evaluation_metrics\n",
    "\n",
    "        # Save model\n",
    "        file_name = f\"r{round_number}_{model.name}_{learning_rate:.0e}_{batch_size}\"\n",
    "        model.save(f\"{file_name}.keras\")\n",
    "        history.to_csv(f\"{file_name}.csv\")\n",
    "\n",
    "        # Save results dict\n",
    "        with open(\"results.pkl\", \"wb\") as results_file:\n",
    "            pickle.dump(results, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836097c",
   "metadata": {
    "papermill": {
     "duration": 0.022014,
     "end_time": "2025-07-02T04:04:10.922757",
     "exception": false,
     "start_time": "2025-07-02T04:04:10.900743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6187980,
     "sourceId": 10061785,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22881.228793,
   "end_time": "2025-07-02T04:04:16.497015",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-01T21:42:55.268222",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
