{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d897bcda",
   "metadata": {
    "_cell_guid": "48c7af20-c871-47dc-b1ec-343e363052c1",
    "_uuid": "18327734-7d09-4829-9a15-8e658b5c1004",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:42.311699Z",
     "iopub.status.busy": "2025-07-07T18:38:42.311429Z",
     "iopub.status.idle": "2025-07-07T18:38:57.249736Z",
     "shell.execute_reply": "2025-07-07T18:38:57.249154Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 14.945895,
     "end_time": "2025-07-07T18:38:57.251114",
     "exception": false,
     "start_time": "2025-07-07T18:38:42.305219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 18:38:46.461586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751913526.654631      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751913526.705841      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf1064",
   "metadata": {
    "_cell_guid": "e2249fc9-3504-407d-a631-f269d46fb0e6",
    "_uuid": "b0451d4a-acdb-4e24-88e3-3cdd792c8d00",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004083,
     "end_time": "2025-07-07T18:38:57.259966",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.255883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54446a29",
   "metadata": {
    "_cell_guid": "6aecae12-dd65-40d8-bcb1-1450a2a85e46",
    "_uuid": "639b6a4a-3705-48e6-8d05-114764f974df",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.269343Z",
     "iopub.status.busy": "2025-07-07T18:38:57.268887Z",
     "iopub.status.idle": "2025-07-07T18:38:57.276445Z",
     "shell.execute_reply": "2025-07-07T18:38:57.275936Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013513,
     "end_time": "2025-07-07T18:38:57.277540",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.264027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "    \n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "\n",
    "@tf.function\n",
    "def eva(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "\n",
    "    numerator = tf.math.reduce_variance(y_true - y_pred)\n",
    "    denominator = tf.math.reduce_variance(y_true) + K.epsilon()\n",
    "    \n",
    "    return 1.0 - numerator / denominator\n",
    "\n",
    "@tf.function\n",
    "def r2_score(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    y_true = tf.reshape(y_true, [-1, 1])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 1])\n",
    "    \n",
    "    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    \n",
    "    return 1 - (ss_res / (ss_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e2a63",
   "metadata": {
    "_cell_guid": "56054a2d-9f1a-431c-bf86-addf35a32d15",
    "_uuid": "8e31442d-2988-4877-8669-5c050e433577",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.00395,
     "end_time": "2025-07-07T18:38:57.285589",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.281639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. ResNet 8/18/34 construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0fec3a9",
   "metadata": {
    "_cell_guid": "1be019cf-24ef-4c07-86ff-ec1f5512f345",
    "_uuid": "3d090588-5da5-4573-a51c-dbd244849ae0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.294599Z",
     "iopub.status.busy": "2025-07-07T18:38:57.294384Z",
     "iopub.status.idle": "2025-07-07T18:38:57.299126Z",
     "shell.execute_reply": "2025-07-07T18:38:57.298476Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01027,
     "end_time": "2025-07-07T18:38:57.300094",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.289824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resnet_block(x, filters, stride=1, use_projection=False):\n",
    "    shortcut = x\n",
    "\n",
    "    x = keras.layers.Conv2D(filters, 3, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters, 3, strides=1, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if use_projection:\n",
    "        shortcut = keras.layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n",
    "        shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = keras.layers.Add()([x, shortcut])\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d811ece5",
   "metadata": {
    "_cell_guid": "8bd2caca-cac2-46fb-af60-daed7e9533fc",
    "_uuid": "345e7309-336c-4662-bcfe-6d7c8217beba",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.309014Z",
     "iopub.status.busy": "2025-07-07T18:38:57.308800Z",
     "iopub.status.idle": "2025-07-07T18:38:57.313691Z",
     "shell.execute_reply": "2025-07-07T18:38:57.312802Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011046,
     "end_time": "2025-07-07T18:38:57.315186",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.304140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet8_DroNet(input_shape=(200, 200, 1), dropout_rate=0.3):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = keras.layers.Conv2D(32, 5, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    x = resnet_block(x, 32)\n",
    "    x = resnet_block(x, 32)\n",
    "\n",
    "    x = resnet_block(x, 64, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 128)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a216e006",
   "metadata": {
    "_cell_guid": "52de183d-1a21-4af5-9c1b-b5076bd6d55d",
    "_uuid": "133c3564-9f2e-4f71-a503-5f862da2efe4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.324567Z",
     "iopub.status.busy": "2025-07-07T18:38:57.324040Z",
     "iopub.status.idle": "2025-07-07T18:38:57.329147Z",
     "shell.execute_reply": "2025-07-07T18:38:57.328487Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010749,
     "end_time": "2025-07-07T18:38:57.330137",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.319388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet18(input_shape=(224, 224, 3)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Conv2_x\n",
    "    x = resnet_block(x, 64)\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "    # Conv3_x\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 128)\n",
    "\n",
    "    # Conv4_x\n",
    "    x = resnet_block(x, 256, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 256)\n",
    "\n",
    "    # Conv5_x\n",
    "    x = resnet_block(x, 512, stride=2, use_projection=True)\n",
    "    x = resnet_block(x, 512)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237dbbe9",
   "metadata": {
    "_cell_guid": "dac5463b-4f8a-42cd-a4e7-e8e04be7b211",
    "_uuid": "eb75c7f9-2425-49c5-bcd0-01e5c06bb261",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.338808Z",
     "iopub.status.busy": "2025-07-07T18:38:57.338575Z",
     "iopub.status.idle": "2025-07-07T18:38:57.343508Z",
     "shell.execute_reply": "2025-07-07T18:38:57.343041Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01036,
     "end_time": "2025-07-07T18:38:57.344521",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.334161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ResNet34(input_shape=(224, 224, 3)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = keras.layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Conv2_x (3 blocks)\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 64)\n",
    "\n",
    "    # Conv3_x (4 blocks)\n",
    "    x = resnet_block(x, 128, stride=2, use_projection=True)\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 128)\n",
    "\n",
    "    # Conv4_x (6 blocks)\n",
    "    x = resnet_block(x, 256, stride=2, use_projection=True)\n",
    "    for _ in range(5):\n",
    "        x = resnet_block(x, 256)\n",
    "\n",
    "    # Conv5_x (3 blocks)\n",
    "    x = resnet_block(x, 512, stride=2, use_projection=True)\n",
    "    for _ in range(2):\n",
    "        x = resnet_block(x, 512)\n",
    "\n",
    "    return keras.models.Model(inputs, x, name=\"ResNet-34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d5db8",
   "metadata": {
    "_cell_guid": "fd3cfe87-bae9-4c16-97b2-44f1c3379230",
    "_uuid": "b22c0b13-3a6d-468b-9bfc-c42201818ba8",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003822,
     "end_time": "2025-07-07T18:38:57.352348",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.348526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Grid search configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348aabb7",
   "metadata": {
    "_cell_guid": "1ad92ad8-a655-4d98-9040-fa2487a58525",
    "_uuid": "f7dc6b5b-89dc-4957-8016-4af0ae1eb566",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.361483Z",
     "iopub.status.busy": "2025-07-07T18:38:57.360995Z",
     "iopub.status.idle": "2025-07-07T18:38:57.364349Z",
     "shell.execute_reply": "2025-07-07T18:38:57.363704Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009124,
     "end_time": "2025-07-07T18:38:57.365350",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.356226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "configurations = list(product([1e-2, 1e-3], [32, 64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e13e16",
   "metadata": {
    "_cell_guid": "bce54cf0-ec2b-4b10-ba1a-cd3ba0ab67ac",
    "_uuid": "aa575dab-d955-4d7c-9265-6f4524a1b6b6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.00377,
     "end_time": "2025-07-07T18:38:57.373075",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.369305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f03acee5",
   "metadata": {
    "_cell_guid": "2e03f5fc-8a07-4fd1-aadd-88ccc81f08ce",
    "_uuid": "132e243b-9b0f-46d8-adeb-4cc4a92467b4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.382316Z",
     "iopub.status.busy": "2025-07-07T18:38:57.382081Z",
     "iopub.status.idle": "2025-07-07T18:38:57.388287Z",
     "shell.execute_reply": "2025-07-07T18:38:57.387587Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011998,
     "end_time": "2025-07-07T18:38:57.389424",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.377426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_descriptions = [\n",
    "    {\n",
    "        \"name\": \"EfficientNetB0-base\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"EfficientNetB0\",\n",
    "            \"weights\": \"imagenet\",\n",
    "        },\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"EfficientNetB0-D20\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"EfficientNetB0\",\n",
    "            \"weights\": \"imagenet\",\n",
    "        },\n",
    "        \"dropout_rate\": 0.2,\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },    {\n",
    "        \"name\": \"EfficientNetB0-D50\",\n",
    "        \"backbone\": {\n",
    "            \"name\": \"EfficientNetB0\",\n",
    "            \"weights\": \"imagenet\",\n",
    "        },\n",
    "        \"dropout_rate\": 0.5,\n",
    "        \"input\": {\n",
    "            \"shape\": [224, 224, 3],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Format verification\n",
    "for model_description in models_descriptions:\n",
    "    if \"backbone\" not in model_description:\n",
    "        raise KeyError(\"backbone not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"name\" not in model_description[\"backbone\"]:\n",
    "        raise KeyError(\"backbone.name not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"weights\" not in model_description[\"backbone\"]:\n",
    "        model_description[\"backbone\"][\"weights\"] = None\n",
    "\n",
    "    if \"freeze\" not in model_description[\"backbone\"]:\n",
    "        model_description[\"backbone\"][\"freeze\"] = True\n",
    "    \n",
    "    if \"name\" not in model_description:\n",
    "        model_description[\"name\"] = model_description[\"backbone\"][\"name\"]\n",
    "\n",
    "    if \"input\" not in model_description:\n",
    "        raise KeyError(\"input not specified at:\\n\" + str(model_description))\n",
    "\n",
    "    if \"shape\" not in model_description[\"input\"]:\n",
    "        raise KeyError(\"input.shape not specified at:\\n\" + str(model_description))\n",
    "    \n",
    "    if \"grayscale\" not in model_description[\"input\"]:\n",
    "        model_description[\"input\"][\"grayscale\"] = False\n",
    "\n",
    "    if \"head_description\" not in model_description:\n",
    "        model_description[\"head_description\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1b94d",
   "metadata": {
    "_cell_guid": "cb902e51-35cb-43f3-8afc-6814b8c30074",
    "_uuid": "e7edca1c-ab6d-44f1-95df-43703274f643",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003814,
     "end_time": "2025-07-07T18:38:57.397125",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.393311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load dataset and build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6564e6a3",
   "metadata": {
    "_cell_guid": "65b52cc1-a092-4150-9c99-2ca6989c8927",
    "_uuid": "67d38f9d-aee5-40ec-9e09-c996fdc0b824",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.405639Z",
     "iopub.status.busy": "2025-07-07T18:38:57.405429Z",
     "iopub.status.idle": "2025-07-07T18:38:57.409588Z",
     "shell.execute_reply": "2025-07-07T18:38:57.408898Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.00957,
     "end_time": "2025-07-07T18:38:57.410624",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.401054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_samples_dataframe(path: str):\n",
    "    images_folder = os.path.join(path, \"images\")\n",
    "\n",
    "    samples_df = pd.read_csv(\n",
    "        os.path.join(path, \"market_dataset_xy.txt\"),\n",
    "        sep=\" \",\n",
    "        header=None,\n",
    "        names=[\"file path\", \"_\", \"datetime\", \"vel_y\", \"vel_x\"]\n",
    "    )\n",
    "\n",
    "    samples_df[\"file path\"] = (\n",
    "        samples_df[\"file path\"]\n",
    "        .apply(lambda image_name: os.path.join(path, \"images\", image_name))\n",
    "    )\n",
    "    \n",
    "    return samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48d0d46",
   "metadata": {
    "_cell_guid": "c295f82a-7a1b-4efc-b56a-3a24c7f7ece3",
    "_uuid": "56dfb498-8b9e-4780-87d0-9161aa992e35",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.419435Z",
     "iopub.status.busy": "2025-07-07T18:38:57.419044Z",
     "iopub.status.idle": "2025-07-07T18:38:57.425954Z",
     "shell.execute_reply": "2025-07-07T18:38:57.425435Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012424,
     "end_time": "2025-07-07T18:38:57.427014",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.414590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_train_val_test_datasets(samples_dataframe, input_description: dict, seed=42):\n",
    "    resolution = input_description[\"shape\"][:2]\n",
    "    channels = input_description[\"shape\"][2]\n",
    "\n",
    "    df_train, df_temp = train_test_split(samples_dataframe, test_size=0.4, random_state=seed)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=seed)\n",
    "\n",
    "    if not input_description[\"grayscale\"]:\n",
    "        mode = \"color\"\n",
    "    elif channels == 1:\n",
    "        mode = \"grayscale1\"\n",
    "    elif channels == 3:\n",
    "        mode = \"grayscale3\"\n",
    "\n",
    "    @tf.function\n",
    "    def process_sample(path, label):\n",
    "        image = tf.io.read_file(path)\n",
    "\n",
    "        if mode == \"color\":\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "        elif mode == \"grayscale1\":\n",
    "            image = tf.image.decode_jpeg(image, channels=1)\n",
    "    \n",
    "        elif mode == \"grayscale3\":\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "            image = tf.image.rgb_to_grayscale(image)\n",
    "            image = tf.image.grayscale_to_rgb(image)\n",
    "\n",
    "        image = tf.image.resize(image, resolution)\n",
    "        image.set_shape(input_description[\"shape\"])\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def df_to_tf_dataset(df):\n",
    "        paths = tf.constant(df[\"file path\"].tolist())\n",
    "        vel_x = tf.constant(df[\"vel_x\"].astype(\"float32\").tolist())\n",
    "        vel_y = tf.constant(df[\"vel_y\"].astype(\"float32\").tolist())\n",
    "    \n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, {\"vel_x\": vel_x, \"vel_y\": vel_y}))\n",
    "\n",
    "        ds = ds.map(process_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.cache()\n",
    "    \n",
    "        return ds\n",
    "\n",
    "    return {\n",
    "        \"train\": df_to_tf_dataset(df_train),\n",
    "        \"val\":   df_to_tf_dataset(df_val),\n",
    "        \"test\":  df_to_tf_dataset(df_test),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e687522d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.436212Z",
     "iopub.status.busy": "2025-07-07T18:38:57.435793Z",
     "iopub.status.idle": "2025-07-07T18:38:57.441096Z",
     "shell.execute_reply": "2025-07-07T18:38:57.440545Z"
    },
    "papermill": {
     "duration": 0.010892,
     "end_time": "2025-07-07T18:38:57.442082",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.431190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_augment_function(gen):\n",
    "    @tf.function\n",
    "    def augment(image, label):\n",
    "        delta = gen.uniform([], minval=-0.2, maxval=0.2)\n",
    "        image = tf.image.adjust_brightness(image, delta * 255.0)\n",
    "        \n",
    "        contrast_factor = gen.uniform([], minval=0.8, maxval=1.2)\n",
    "        image = tf.image.adjust_contrast(image, contrast_factor)\n",
    "        \n",
    "        noise = gen.normal(tf.shape(image), mean=0.0, stddev=0.025 * 255.0)\n",
    "        image = image + noise\n",
    "        image = tf.clip_by_value(image, 0.0, 255.0)\n",
    "        \n",
    "        do_flip = gen.uniform([], minval=0, maxval=1) > 0.5\n",
    "        image = tf.cond(do_flip, lambda: tf.image.flip_left_right(image), lambda: image)\n",
    "        \n",
    "        vel_x = tf.cond(do_flip, lambda: -label[\"vel_x\"], lambda: label[\"vel_x\"])\n",
    "        vel_y = label[\"vel_y\"]\n",
    "        \n",
    "        return image, {\"vel_x\": vel_x, \"vel_y\": vel_y}\n",
    "\n",
    "    return augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a930f586",
   "metadata": {
    "_cell_guid": "73ef85f1-0fde-44cd-9fa7-00eeb5dc8ab6",
    "_uuid": "e8df451c-01ec-407d-b878-7759d50d129d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.450959Z",
     "iopub.status.busy": "2025-07-07T18:38:57.450741Z",
     "iopub.status.idle": "2025-07-07T18:38:57.459383Z",
     "shell.execute_reply": "2025-07-07T18:38:57.458692Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014361,
     "end_time": "2025-07-07T18:38:57.460499",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.446138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def instantiate_backbone(backbone_name, weights=None):\n",
    "    if backbone_name == \"ResNet-8\":\n",
    "        if not weights:\n",
    "            return ResNet8_DroNet(input_shape=(200, 200, 1))\n",
    "        elif weights == \"dronet\":\n",
    "            model = keras.models.load_model(\"/kaggle/input/marketplace-navigation-dataset/model.keras\", compile=True)\n",
    "            model.name = \"ResNet-8\"\n",
    "            return model\n",
    "        else:\n",
    "            raise ValueError(\"No\", weights, \"weights found for\", backbone_name)\n",
    "    \n",
    "    if backbone_name == \"ResNet-18\":\n",
    "        if weights is not None:\n",
    "            raise ValueError(\"No\", weights, \"weights found for\", backbone_name)\n",
    "        return ResNet18(input_shape=(224, 224, 3))\n",
    "        \n",
    "    if backbone_name == \"ResNet-34\":\n",
    "        if weights is not None:\n",
    "            raise ValueError(\"No\", weights, \"weights found for\", backbone_name)\n",
    "        return ResNet34(input_shape=(224, 224, 3))\n",
    "\n",
    "    if backbone_name == \"ResNet-50\":\n",
    "        assert not weights or weights in [\"imagenet\"], \"No \" + weights + \" weights found for \" + backbone_name\n",
    "        return keras.applications.ResNet50(\n",
    "            name=\"ResNet-50\",\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=weights,\n",
    "            pooling=None,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"ResNet-50V2\":\n",
    "        assert not weights or weights in [\"imagenet\"], \"No \" + weights + \" weights found for \" + backbone_name\n",
    "        return keras.applications.ResNet50V2(\n",
    "            name=\"ResNet-50V2\",\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=weights,\n",
    "            pooling=None,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"MobileNet\":\n",
    "        assert not weights or weights in [\"imagenet\"], \"No \" + weights + \" weights found for \" + backbone_name\n",
    "        return keras.applications.MobileNet(\n",
    "            name=\"MobileNet\",\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=weights,\n",
    "            pooling=None,\n",
    "            alpha=1.0,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"MobileNetV2\":\n",
    "        assert not weights or weights in [\"imagenet\"], \"No \" + weights + \" weights found for \" + backbone_name\n",
    "        return keras.applications.MobileNetV2(\n",
    "            name=\"MobileNetV2\",\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=weights,\n",
    "            pooling=None,\n",
    "            alpha=1.0,\n",
    "        )\n",
    "\n",
    "    if backbone_name == \"EfficientNetB0\":\n",
    "        assert not weights or weights in [\"imagenet\"], \"No \" + weights + \" weights found for \" + backbone_name\n",
    "        # As of 04/07/2025, setting name=\"EfficientNetB0\" causes a\n",
    "        # HTTP error for reasons that neither I or ChatGPT can comprehend\n",
    "        # return keras.applications.EfficientNetB0(\n",
    "        #     include_top=False,\n",
    "        #     name=\"EfficientNetB0\",\n",
    "        #     input_shape=(224, 224, 3),\n",
    "        #     weights=weights,\n",
    "        #     pooling=None,\n",
    "        # )\n",
    "\n",
    "        # This should work\n",
    "        model = keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=weights,\n",
    "            pooling=None,\n",
    "        )\n",
    "        model.name = \"EfficientNetB0\"\n",
    "        return model\n",
    "    \n",
    "    raise ValueError(f\"Backbone {backbone_name} not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfab2c98",
   "metadata": {
    "_cell_guid": "ab542392-8959-44aa-a187-759691580111",
    "_uuid": "63607edb-cb23-44b6-8f51-5c9b71882a2b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.469703Z",
     "iopub.status.busy": "2025-07-07T18:38:57.469492Z",
     "iopub.status.idle": "2025-07-07T18:38:57.477380Z",
     "shell.execute_reply": "2025-07-07T18:38:57.476845Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013899,
     "end_time": "2025-07-07T18:38:57.478583",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.464684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(model_description: dict):\n",
    "    input_shape = model_description[\"input\"][\"shape\"]\n",
    "    input_shape = tuple(input_shape)\n",
    "\n",
    "    backbone_name = model_description[\"backbone\"][\"name\"]\n",
    "    backbone_weights = model_description[\"backbone\"][\"weights\"]\n",
    "    freeze_backbone = model_description[\"backbone\"][\"freeze\"]\n",
    "\n",
    "    model_name = model_description.get(\"name\", backbone_name)\n",
    "    dropout_rate = model_description.get(\"dropout_rate\", None)\n",
    "\n",
    "    PREPROCESS = {\n",
    "        \"ResNet-8\":        lambda x: x / 255.0,\n",
    "        \"ResNet-18\":       lambda x: x / 255.0,\n",
    "        \"ResNet-34\":       lambda x: x / 255.0,\n",
    "        \"MobileNet\":       keras.applications.mobilenet.preprocess_input,\n",
    "        \"MobileNetV2\":     keras.applications.mobilenet_v2.preprocess_input,\n",
    "        \"ResNet-50\":       keras.applications.resnet.preprocess_input,\n",
    "        \"ResNet-50V2\":     keras.applications.resnet_v2.preprocess_input,\n",
    "        \"EfficientNetB0\":  keras.applications.efficientnet.preprocess_input,\n",
    "    }\n",
    "\n",
    "    backbone = instantiate_backbone(backbone_name, weights=backbone_weights)\n",
    "    backbone.trainable = not freeze_backbone\n",
    "\n",
    "    inputs = keras.layers.Input(input_shape)\n",
    "    x = PREPROCESS.get(backbone_name, lambda x: x)(inputs)\n",
    "    x = backbone(x)\n",
    "\n",
    "    if backbone_name == \"ResNet-8\":\n",
    "        x = keras.layers.Flatten(name=\"flatten\")(x)\n",
    "        x = keras.layers.ReLU(name=\"flatten_ReLU\")(x)\n",
    "    else:\n",
    "        x = keras.layers.GlobalAveragePooling2D(name=\"global_pool\")(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = keras.layers.Dropout(dropout_rate, name=\"head_dropout\")(x)\n",
    "        print(\"[TEST] Added\", dropout_rate, \"dropout to\", model_name)\n",
    "\n",
    "    for i, (nodes, use_batch_normalization, use_dropout) in enumerate(model_description[\"head_description\"]):\n",
    "        use_bias = not use_batch_normalization\n",
    "        \n",
    "        x = keras.layers.Dense(nodes, use_bias=use_bias, activation=\"linear\", name=f\"dense_{i}\")(x)\n",
    "\n",
    "        if use_batch_normalization:\n",
    "            x = keras.layers.BatchNormalization(name=f\"batchnorm_{i}\")(x)\n",
    "\n",
    "        x = keras.layers.ReLU(name=f\"relu_{i}\")(x)\n",
    "        \n",
    "        if use_dropout:\n",
    "            x = keras.layers.Dropout(0.5, name=f\"dropout_{i}\")(x)\n",
    "    \n",
    "    output_x = keras.layers.Dense(1, name=\"vel_x\")(x)\n",
    "    output_y = keras.layers.Dense(1, name=\"vel_y\")(x)\n",
    "\n",
    "    outputs = {\n",
    "        \"vel_x\": output_x,\n",
    "        \"vel_y\": output_y,\n",
    "    }\n",
    "\n",
    "    return keras.models.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        name=model_description.get(\"name\", backbone_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a09914",
   "metadata": {
    "_cell_guid": "a233e2ac-4e1f-4a42-a111-d411949ff083",
    "_uuid": "8aee1451-2625-4828-8fb5-8774c8a59bf2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003762,
     "end_time": "2025-07-07T18:38:57.486427",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.482665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Results structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af69d5bb",
   "metadata": {
    "_cell_guid": "1991cb1d-94cf-45f8-8ef0-871519578537",
    "_uuid": "73603bbb-2aef-4892-ad9b-1b24beb06264",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.495516Z",
     "iopub.status.busy": "2025-07-07T18:38:57.495240Z",
     "iopub.status.idle": "2025-07-07T18:38:57.498827Z",
     "shell.execute_reply": "2025-07-07T18:38:57.498129Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009289,
     "end_time": "2025-07-07T18:38:57.499946",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.490657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_description in models_descriptions:\n",
    "    model_name = model_description[\"name\"]\n",
    "    \n",
    "    results[model_name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15cae1b",
   "metadata": {
    "_cell_guid": "f3867308-442f-4792-bf73-613cc1d2fd86",
    "_uuid": "31991ed3-ecc8-4e67-a133-fdc2bc704f35",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.508796Z",
     "iopub.status.busy": "2025-07-07T18:38:57.508592Z",
     "iopub.status.idle": "2025-07-07T18:38:57.514851Z",
     "shell.execute_reply": "2025-07-07T18:38:57.514167Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011934,
     "end_time": "2025-07-07T18:38:57.515870",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.503936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_predictions_h5(model, test_ds, file_path: str):\n",
    "    all_true_vel_x = []\n",
    "    all_pred_vel_x = []\n",
    "    all_true_vel_y = []\n",
    "    all_pred_vel_y = []\n",
    "\n",
    "    for images, labels in test_ds:\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        \n",
    "        if isinstance(preds, (list, tuple)):\n",
    "            pred_vel_x, pred_vel_y = preds\n",
    "        elif isinstance(preds, dict):\n",
    "            pred_vel_x, pred_vel_y = preds[\"vel_x\"], preds[\"vel_y\"]\n",
    "        else:\n",
    "            raise ValueError(\"Formato de saída inesperado de model.predict.\")\n",
    "\n",
    "        all_true_vel_x.append(labels[\"vel_x\"].numpy())\n",
    "        all_pred_vel_x.append(pred_vel_x)\n",
    "\n",
    "        all_true_vel_y.append(labels[\"vel_y\"].numpy())\n",
    "        all_pred_vel_y.append(pred_vel_y)\n",
    "\n",
    "    all_true_vel_x = np.concatenate(all_true_vel_x, axis=0)\n",
    "    all_pred_vel_x = np.concatenate(all_pred_vel_x, axis=0)\n",
    "\n",
    "    all_true_vel_y = np.concatenate(all_true_vel_y, axis=0)\n",
    "    all_pred_vel_y = np.concatenate(all_pred_vel_y, axis=0)\n",
    "\n",
    "    with h5py.File(file_path, \"w\") as f:\n",
    "        f.create_dataset(\"true_vel_x\", data=all_true_vel_x)\n",
    "        f.create_dataset(\"pred_vel_x\", data=all_pred_vel_x)\n",
    "        f.create_dataset(\"true_vel_y\", data=all_true_vel_y)\n",
    "        f.create_dataset(\"pred_vel_y\", data=all_pred_vel_y)\n",
    "\n",
    "    print(f\"[INFO] True and predicted labels saved in {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8090a0",
   "metadata": {
    "_cell_guid": "8de5ae77-1bab-4d5d-af50-c51330a66566",
    "_uuid": "e936165a-3a18-4bdd-a31d-4e895df1109e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003801,
     "end_time": "2025-07-07T18:38:57.523832",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.520031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Benchmark loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32814d46",
   "metadata": {
    "_cell_guid": "e8db766d-6a05-4f7d-af56-e8d612c886d9",
    "_kg_hide-output": true,
    "_uuid": "14699042-cc09-46ea-8772-90fcd9641d0c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-07T18:38:57.533001Z",
     "iopub.status.busy": "2025-07-07T18:38:57.532793Z",
     "iopub.status.idle": "2025-07-07T20:48:05.097781Z",
     "shell.execute_reply": "2025-07-07T20:48:05.097100Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7747.57131,
     "end_time": "2025-07-07T20:48:05.099204",
     "exception": false,
     "start_time": "2025-07-07T18:38:57.527894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751913539.257191      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model EfficientNetB0-base for configuration LR = 0.01 , BS = 32\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751913584.146040      59 service.cc:148] XLA service 0x7d7d10151ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751913584.149329      59 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1751913585.889775      59 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1751913594.325541      59 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Unfrozen layer EfficientNetB0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1751913792.914370      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751913793.105204      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751913793.577409      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751913793.783740      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751913794.147934      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751913794.354122      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] True and predicted labels saved in EfficientNetB0-base_1e-02_32.h5\n",
      "Training model EfficientNetB0-D20 for configuration LR = 0.01 , BS = 32\n",
      "[TEST] Added 0.2 dropout to EfficientNetB0-D20\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D20_1e-02_32.h5\n",
      "Training model EfficientNetB0-D50 for configuration LR = 0.01 , BS = 32\n",
      "[TEST] Added 0.5 dropout to EfficientNetB0-D50\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D50_1e-02_32.h5\n",
      "Training model EfficientNetB0-base for configuration LR = 0.01 , BS = 64\n",
      "[INFO] Unfrozen layer EfficientNetB0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1751915823.170023      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751915823.364115      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751915823.910889      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751915824.118864      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751915824.509943      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1751915824.717878      56 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] True and predicted labels saved in EfficientNetB0-base_1e-02_64.h5\n",
      "Training model EfficientNetB0-D20 for configuration LR = 0.01 , BS = 64\n",
      "[TEST] Added 0.2 dropout to EfficientNetB0-D20\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D20_1e-02_64.h5\n",
      "Training model EfficientNetB0-D50 for configuration LR = 0.01 , BS = 64\n",
      "[TEST] Added 0.5 dropout to EfficientNetB0-D50\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D50_1e-02_64.h5\n",
      "Training model EfficientNetB0-base for configuration LR = 0.001 , BS = 32\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-base_1e-03_32.h5\n",
      "Training model EfficientNetB0-D20 for configuration LR = 0.001 , BS = 32\n",
      "[TEST] Added 0.2 dropout to EfficientNetB0-D20\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D20_1e-03_32.h5\n",
      "Training model EfficientNetB0-D50 for configuration LR = 0.001 , BS = 32\n",
      "[TEST] Added 0.5 dropout to EfficientNetB0-D50\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D50_1e-03_32.h5\n",
      "Training model EfficientNetB0-base for configuration LR = 0.001 , BS = 64\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-base_1e-03_64.h5\n",
      "Training model EfficientNetB0-D20 for configuration LR = 0.001 , BS = 64\n",
      "[TEST] Added 0.2 dropout to EfficientNetB0-D20\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D20_1e-03_64.h5\n",
      "Training model EfficientNetB0-D50 for configuration LR = 0.001 , BS = 64\n",
      "[TEST] Added 0.5 dropout to EfficientNetB0-D50\n",
      "[INFO] Unfrozen layer EfficientNetB0\n",
      "[INFO] True and predicted labels saved in EfficientNetB0-D50_1e-03_64.h5\n"
     ]
    }
   ],
   "source": [
    "samples_dataframe = load_samples_dataframe(\"/kaggle/input/marketplace-navigation-dataset/dataset\")\n",
    "\n",
    "seed = 0\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for model_description in models_descriptions:\n",
    "    dataset_key = tuple(model_description[\"input\"][\"shape\"])\n",
    "    dataset_key = model_description[\"input\"][\"grayscale\"], dataset_key\n",
    "    \n",
    "    if not dataset_key in datasets:\n",
    "        datasets[dataset_key] = build_train_val_test_datasets(\n",
    "            samples_dataframe,\n",
    "            model_description[\"input\"],\n",
    "            seed\n",
    "        )\n",
    "        \n",
    "for learning_rate, batch_size in configurations:\n",
    "    for model_description in models_descriptions:\n",
    "        print(\n",
    "            \"Training model\", model_description[\"name\"],\n",
    "            \"for configuration LR =\", learning_rate, \", BS =\", batch_size \n",
    "        )\n",
    "        \n",
    "        dataset_key = tuple(model_description[\"input\"][\"shape\"])\n",
    "        dataset_key = model_description[\"input\"][\"grayscale\"], dataset_key\n",
    "\n",
    "        train_ds = datasets[dataset_key][\"train\"]\n",
    "        val_ds   = datasets[dataset_key][\"val\"]\n",
    "        test_ds  = datasets[dataset_key][\"test\"]\n",
    "\n",
    "        gen = tf.random.Generator.from_seed(seed)\n",
    "        augment = get_augment_function(gen)\n",
    "\n",
    "        train_ds = train_ds.shuffle(train_ds.cardinality(), seed=seed, reshuffle_each_iteration=True)\n",
    "        train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        train_ds = train_ds.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "        val_ds   = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        test_ds  = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        model = build_model(model_description)\n",
    "        model.compile(\n",
    "            loss={\n",
    "                \"vel_x\": \"mean_squared_error\",\n",
    "                \"vel_y\": \"mean_squared_error\",\n",
    "            },\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            metrics={\n",
    "                \"vel_x\": [rmse, eva, r2_score],\n",
    "                \"vel_y\": [rmse, eva, r2_score],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        history_1 = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=200,\n",
    "            verbose=0,\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=15,\n",
    "                    min_delta=1e-4,\n",
    "                    mode=\"min\",\n",
    "                    restore_best_weights=True,\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        for layer in model.layers:\n",
    "            if layer.name == model_description[\"backbone\"][\"name\"]:\n",
    "                layer.trainable = True\n",
    "                print(\"[INFO] Unfrozen layer\", layer.name)\n",
    "        \n",
    "        model.compile(\n",
    "            loss={\n",
    "                \"vel_x\": \"mean_squared_error\",\n",
    "                \"vel_y\": \"mean_squared_error\",\n",
    "            },\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate * 0.1),\n",
    "            metrics={\n",
    "                \"vel_x\": [rmse, eva, r2_score],\n",
    "                \"vel_y\": [rmse, eva, r2_score],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        history_2 = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            verbose=0,\n",
    "            epochs=200,\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=15,\n",
    "                    min_delta=1e-4,\n",
    "                    mode=\"min\",\n",
    "                    restore_best_weights=True,\n",
    "                ),\n",
    "                keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=5,\n",
    "                    factor=0.5,\n",
    "                    min_lr=1e-7,\n",
    "                    mode=\"min\"\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "        history = pd.concat([\n",
    "            pd.DataFrame(history_1.history),\n",
    "            pd.DataFrame(history_2.history),\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "        metrics = model.evaluate(test_ds, return_dict=True, verbose=0)\n",
    "        \n",
    "        results[model_description[\"name\"]].append({\n",
    "            \"learning rate\": learning_rate,\n",
    "            \"batch size\": batch_size,\n",
    "            \"metrics\": metrics,\n",
    "        })\n",
    "\n",
    "        file_name = f\"{model.name}_{learning_rate:.0e}_{batch_size}\"\n",
    "\n",
    "        model.save(f\"{file_name}.keras\")\n",
    "        history.to_csv(f\"{file_name}.csv\")\n",
    "        store_predictions_h5(model, test_ds, f\"{file_name}.h5\")\n",
    "        \n",
    "        with open(\"results.json\", \"w\") as results_file:\n",
    "            results_file.write(json.dumps(results, indent=True))\n",
    "\n",
    "        del model\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f60675",
   "metadata": {
    "papermill": {
     "duration": 0.007557,
     "end_time": "2025-07-07T20:48:05.114868",
     "exception": false,
     "start_time": "2025-07-07T20:48:05.107311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6187980,
     "sourceId": 10061785,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7772.430986,
   "end_time": "2025-07-07T20:48:10.662596",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T18:38:38.231610",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
